{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T09:59:48.556463Z",
     "start_time": "2024-11-04T09:59:27.496473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepface import DeepFace\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, os, re, time, logging, cv2, torch\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip"
   ],
   "id": "95b04144a3993352",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\oskik\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T09:29:46.855053Z",
     "start_time": "2024-11-04T09:29:39.766855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "SEQUENCE_LENGTH = 30\n",
    "STRIDE = 1\n",
    "BATCH_SIZE = 32\n",
    "SEQUENCES_PER_VIDEO = 50  # Number of random sequences to sample per video\n",
    "\n",
    "# Helper function to create random sequences\n",
    "def create_random_sequences(features, labels, sequence_length, num_sequences):\n",
    "    x_sequences, y_sequences = [], []\n",
    "    max_start = len(features) - sequence_length\n",
    "    for _ in range(num_sequences):\n",
    "        start_idx = random.randint(0, max_start)  # Random starting index\n",
    "        x_sequences.append(features[start_idx:start_idx + sequence_length])\n",
    "        y_sequences.append(labels[start_idx:start_idx + sequence_length])\n",
    "    return np.array(x_sequences), np.array(y_sequences)\n",
    "\n",
    "# Initialize lists to hold all sequences\n",
    "all_x_sequences = []\n",
    "all_y_sequences = []\n",
    "\n",
    "# Define paths (modify these to match your file structure)\n",
    "input_files = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_input.csv'))\n",
    "label_files = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_BORIS.csv'))\n",
    "\n",
    "# Process each pair of input and label files\n",
    "for input_file, label_file in zip(input_files, label_files):\n",
    "    # Load data\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    label_df = pd.read_csv(label_file)\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    biosignals = input_df[['EDA', 'TEMP', 'HR']].values\n",
    "    embeddings = input_df.iloc[:, 3:].values\n",
    "    features = np.hstack((biosignals, embeddings))\n",
    "    labels = label_df.values\n",
    "    \n",
    "    # Ensure alignment of frames\n",
    "    if features.shape[0] != labels.shape[0]:\n",
    "        print(f\"Mismatch in frames: {input_file}, {label_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Sample random sequences\n",
    "    x_sequences, y_sequences = create_random_sequences(features, labels, SEQUENCE_LENGTH, SEQUENCES_PER_VIDEO)\n",
    "    \n",
    "    # Append to global lists\n",
    "    all_x_sequences.append(x_sequences)\n",
    "    all_y_sequences.append(y_sequences)\n",
    "\n",
    "# Concatenate all sequences from all files\n",
    "all_x_sequences = np.concatenate(all_x_sequences, axis=0)\n",
    "all_y_sequences = np.concatenate(all_y_sequences, axis=0)\n",
    "\n",
    "# Convert to TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_x_sequences, all_y_sequences))\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Verify the dataset\n",
    "for x_batch, y_batch in dataset.take(1):\n",
    "    print(f'Feature batch shape: {x_batch.shape}')\n",
    "    print(f'Label batch shape: {y_batch.shape}')\n"
   ],
   "id": "3269ede97309fd73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch in frames: //153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT\\GUT_S02_C02_input.csv, //153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT\\GUT_S02_C02_BORIS.csv\n",
      "Feature batch shape: (32, 30, 515)\n",
      "Label batch shape: (32, 30, 6)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T10:35:35.332218Z",
     "start_time": "2024-11-04T10:34:57.220180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, re\n",
    "from pathlib import Path\n",
    "from moviepy.editor import VideoFileClip\n",
    "def traverse():\n",
    "    root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE'\n",
    "    boris_ext = 'Analysis/BORIS/'\n",
    "    type = ['Camera', 'Wristband']\n",
    "    research_centers = ['GUT']\n",
    "    #research_centers = ['GUT', 'ITU-YU', 'MAAP']\n",
    "    #s_values = [\"S01\"]\n",
    "    s_values = [\"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\", \"S11\" ]\n",
    "    #c_values = [\"C01\"]\n",
    "    c_values = [\"C01\", \"C02\", \"C03\", \"C04\", \"C05\", \"C06\", \"C07\", \"C08\", \"C09\", \"C10\", \"C11\", \"C12\", \"C13\" ]\n",
    "    for research_center in research_centers:\n",
    "        for session in s_values:\n",
    "            # Create the session path for biosignal and camera + BORIS\n",
    "            camera_path = Path(root_dir).joinpath(type[0], research_center, session)\n",
    "            signals_path = Path(root_dir).joinpath(type[1], research_center, session)\n",
    "            if camera_path.is_dir() and signals_path.is_dir():\n",
    "                # Create the meeting path for biosignal and camera + BORIS\n",
    "                for camera in c_values:\n",
    "                    exact_camera_path = Path(camera_path).joinpath(camera)\n",
    "                    exact_signals_path = Path(signals_path).joinpath(camera)\n",
    "                    if exact_camera_path.is_dir() and exact_signals_path.is_dir():\n",
    "                        boris_path = Path(exact_camera_path).joinpath(boris_ext)\n",
    "                        if boris_path.is_dir():\n",
    "                            # Quick fix of two MAAP sessions being divided TODO: Fix this\n",
    "                            if not(research_center == 'MAAP' and ((session == 'S01' and camera == 'C05') or (session == 'S03' and camera == 'C05'))):\n",
    "                                mp4_video_path = glob.glob(os.path.join(exact_camera_path, \"*.mp4\"))[0]\n",
    "                                with VideoFileClip(mp4_video_path) as video:\n",
    "                                    mp4_duration = video.duration\n",
    "                                mts_video_path = glob.glob(os.path.join(exact_camera_path, \"*.MTS\"))[0]\n",
    "                                with VideoFileClip(mts_video_path) as video:\n",
    "                                    mts_duration = video.duration\n",
    "                                if mp4_duration > mts_duration:\n",
    "                                    print(mp4_video_path)\n",
    "                                else:\n",
    "                                    print(mts_video_path)\n",
    "                                    \n",
    "traverse()\n"
   ],
   "id": "84ac4de51a433f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S01\\C01\\Untitled 139.mp4\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S01\\C02\\00220.MTS\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S01\\C03\\00221.MTS\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S02\\C01\\Untitled 145.mp4\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S02\\C02\\00223.MTS\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S02\\C03\\Untitled 143.mp4\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S03\\C01\\00225.MTS\n",
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S03\\C02\\00226.MTS\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "505f7568b967b339"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
