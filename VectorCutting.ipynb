{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.775052Z",
     "start_time": "2024-11-26T14:25:26.245214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, os, re, time, logging, cv2, torch\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "import pytz\n",
    "import datetime\n",
    "from win32com.propsys import propsys, pscon\n",
    "import subprocess\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.780591Z",
     "start_time": "2024-11-26T14:25:32.776567Z"
    }
   },
   "cell_type": "code",
   "source": "PYCHARM_DEBUG=True",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.797135Z",
     "start_time": "2024-11-26T14:25:32.782596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_table(table):\n",
    "    for row in table:\n",
    "        print(row)\n",
    "\n",
    "def create_II_table(tab1, tab2, tab3):\n",
    "    result_tab = []\n",
    "\n",
    "    for row1, row2, row3 in zip(tab1, tab2, tab3):\n",
    "        sum_rows = [int(a) + int(b) + int(c) for a, b, c in zip(row1[1:], row2[1:], row3[1:])]\n",
    "\n",
    "        total_sum = sum(sum_rows)\n",
    "        if total_sum > 0:\n",
    "            # Calculate the percentage distribution\n",
    "            percentages = [round((x / 3) * 100, 2) for x in sum_rows]\n",
    "        else:\n",
    "            percentages = [0] * len(sum_rows)\n",
    "\n",
    "        result_tab.append([row1[0]] + percentages)\n",
    "\n",
    "    return result_tab\n",
    "\n",
    "def create_I_table(tab1, tab2, tab3):\n",
    "    result_tab = []\n",
    "    \n",
    "    emotions = ['Unknown', 'Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "    \n",
    "    for row1, row2, row3 in zip(tab1, tab2, tab3):\n",
    "        sum_rows = [int(a) + int(b) + int(c) for a, b, c in zip(row1[1:], row2[1:], row3[1:])]\n",
    "        \n",
    "        max_sum = max(sum_rows[1:], default=0)\n",
    "        index = sum_rows.index(max_sum) if max_sum > 1 else -1  # Indeks od 1, jeśli suma jest większa niż 0, w przeciwnym razie -1\n",
    "        \n",
    "        if 0 <= index < len(emotions):\n",
    "            result_tab.append([row1[0], emotions[index]])\n",
    "        else:\n",
    "            result_tab.append([row1[0], 'None'])\n",
    "    return result_tab\n",
    "\n",
    "# Makes table equal\n",
    "def fill_table(table, csvreader):\n",
    "    seconds = 0\n",
    "    stop = 0\n",
    "    for row in csvreader:\n",
    "        row[0] = int(row[0].split('.')[0])\n",
    "        if seconds <= row[0] and stop == 0:  #fill table with missing seconds\n",
    "            for i in range(0, row[0]):\n",
    "                table.append([i, '0', '0', '0', '0', '0', '0', '0'])\n",
    "                seconds += 1\n",
    "            stop = 1\n",
    "            table.append(row)\n",
    "        else:\n",
    "            table.append(row)\n",
    "\n",
    "\n",
    "# Create percentages for every second\n",
    "def csv_files_reader(base_path):\n",
    "    index = ['I', 'II', 'III']\n",
    "    tab1 = []\n",
    "    tab2 = []\n",
    "    tab3 = []\n",
    "\n",
    "    if os.path.exists(base_path):\n",
    "\n",
    "        for i in index:\n",
    "            file = os.path.join(base_path, i)\n",
    "            for file_name in os.listdir(file):\n",
    "                file_path = os.path.join(file, file_name)\n",
    "\n",
    "                with open(file_path, 'r') as file:\n",
    "                    csvreader = csv.reader(file)\n",
    "                    header = next(csvreader)\n",
    "\n",
    "                    if i == 'I':\n",
    "                        fill_table(tab1, csvreader)\n",
    "                    elif i == 'II':\n",
    "                        fill_table(tab2, csvreader)\n",
    "                    elif i == 'III':\n",
    "                        fill_table(tab3, csvreader)\n",
    "    else:\n",
    "        print(f\"File path {base_path} doesn't exist.\")\n",
    "\n",
    "    large_table = max([tab1, tab2, tab3], key=len)\n",
    "\n",
    "    for tab in [tab1, tab2, tab3]:\n",
    "        if len(tab) < len(large_table):\n",
    "            diff = len(large_table) - len(tab)\n",
    "\n",
    "            if len(tab) == 0:\n",
    "                sec = 0\n",
    "                for sec in range(len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "            else:\n",
    "                sec = tab[-1][0]  #latest second in table\n",
    "                for sec in range(tab[-1][0] + 1, len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "\n",
    "    return create_I_table(tab1, tab2, tab3), create_II_table(tab1, tab2, tab3)\n",
    "\n",
    "\n",
    "def get_boris_vectors(path):\n",
    "    table_I, table_II = csv_files_reader(path)\n",
    "    df1 = pd.DataFrame(table_I)\n",
    "    df2 = pd.DataFrame(table_II)\n",
    "    print(df1)\n",
    "    print(df2)\n",
    "    return df1, df2"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.809737Z",
     "start_time": "2024-11-26T14:25:32.798902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_video_metadata(file_path):\n",
    "    try:\n",
    "        # Get the file status\n",
    "        file_stat = os.stat(file_path)\n",
    "\n",
    "        # Get the last modified time\n",
    "        last_modified_time_str = time.ctime(file_stat.st_mtime)\n",
    "        last_modified_timestamp = int(file_stat.st_mtime)\n",
    "\n",
    "        # Get the duration of the video\n",
    "        with VideoFileClip(file_path) as video:\n",
    "            duration = video.duration\n",
    "\n",
    "        metadata = {\n",
    "            'last_modified_time': last_modified_time_str,\n",
    "            'last_modified_timestamp': last_modified_timestamp,\n",
    "            'duration': int(duration),  # Duration in seconds\n",
    "            'initial_timestamp' : last_modified_timestamp - int(duration)\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return f\"The file {file_path} does not exist.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.819911Z",
     "start_time": "2024-11-26T14:25:32.810743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gut_timestamp(video_path):\n",
    "    return get_video_metadata(video_path)['initial_timestamp']"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.830591Z",
     "start_time": "2024-11-26T14:25:32.820921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ituyu_timestamp(video_path):\n",
    "    try:\n",
    "        properties = propsys.SHGetPropertyStoreFromParsingName(video_path)\n",
    "        timestamp = int(properties.GetValue(pscon.PKEY_Media_DateEncoded).GetValue().timestamp())\n",
    "        return timestamp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving video metadata: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.840417Z",
     "start_time": "2024-11-26T14:25:32.832608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def maap_timestamp(video_path):\n",
    "    try:\n",
    "        # Use ffprobe to extract video metadata\n",
    "        result = subprocess.run(\n",
    "            ['ffprobe.exe', '-v', 'quiet', '-print_format', 'json', '-show_entries', 'format_tags=creation_time', video_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        metadata = json.loads(result.stdout)\n",
    "        \n",
    "        # Extract the creation time if available\n",
    "        creation_time = metadata.get('format', {}).get('tags', {}).get('creation_time', None)\n",
    "        \n",
    "        if creation_time:\n",
    "            creation_datetime = datetime.fromisoformat(creation_time.replace('Z', '+00:00'))\n",
    "            unix_timestamp = int(creation_datetime.timestamp())\n",
    "            return unix_timestamp\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving video metadata: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.851549Z",
     "start_time": "2024-11-26T14:25:32.841422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_video_recording_timestamp(video_path, research_center):\n",
    "    timestamp = 0\n",
    "    if research_center == 'GUT':\n",
    "        timestamp = gut_timestamp(video_path)\n",
    "    elif research_center == 'ITU-YU':\n",
    "        timestamp = ituyu_timestamp(video_path)\n",
    "    elif research_center == 'MAAP':\n",
    "        timestamp = maap_timestamp(video_path)\n",
    "    return timestamp"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.860320Z",
     "start_time": "2024-11-26T14:25:32.852560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the moment of the start of the vector and its frequency\n",
    "def get_unix_and_hz(file_path):\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        unix = int(float(next(reader)[0]))  # Convert the first cell to integer\n",
    "        hz = int(float(next(reader)[0]))  # Convert the second cell to integer\n",
    "    return unix, hz"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.869928Z",
     "start_time": "2024-11-26T14:25:32.863333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trim the vector to be the multiple of its frequency\n",
    "def trim_vector(vector, rate):\n",
    "    length = len(vector)\n",
    "    if length % rate != 0:\n",
    "        # Calculate how many elements need to be removed\n",
    "        excess_elements = length % rate\n",
    "        # Trim the vector\n",
    "        vector = vector[:-excess_elements]\n",
    "    return vector"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.878728Z",
     "start_time": "2024-11-26T14:25:32.870939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change the frequency by averaging the values\n",
    "def mean_of_values(vector, rate):\n",
    "    # Ensure the length of the vector is a multiple of n\n",
    "    if len(vector) % rate != 0:\n",
    "        raise ValueError(\"Length of the vector must be a multiple of frequency\")\n",
    "\n",
    "    # Reshape the vector into a 2D array where each row is a group of n elements\n",
    "    reshaped_vector = np.reshape(vector, (-1, rate))\n",
    "\n",
    "    # Calculate the mean along the rows\n",
    "    mean_values = np.mean(reshaped_vector, axis=1)\n",
    "\n",
    "    return mean_values"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.892698Z",
     "start_time": "2024-11-26T14:25:32.882742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_frame_embeddings(path):\n",
    "    # Step 1: Initialize FaceNet model and MTCNN detector\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)  # MTCNN for face detection\n",
    "    facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)  # Pre-trained FaceNet model\n",
    "    \n",
    "    # Step 2: Load video file and get frame rate\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    else:\n",
    "        print(\"Video opened successfully!\")\n",
    "\n",
    "    # Calculate frames per second (fps) and total frames\n",
    "    frame_interval = cap.get(cv2.CAP_PROP_FPS)  # Frames per second of the video\n",
    "\n",
    "    # Step 3: Process video at 1 second intervals\n",
    "    frame_count = 0\n",
    "    frame_embeddings = []\n",
    "    num_of_features = 512\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Check if the frame is at the 1-second interval\n",
    "        if frame_count % frame_interval < 1:\n",
    "            # Convert frame to RGB (OpenCV uses BGR by default)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            try:\n",
    "                # Step 4: Detect faces in the frame\n",
    "                boxes, _ = mtcnn.detect(frame_pil)\n",
    "                if boxes is not None and len(boxes) > 0:\n",
    "                    # Step 5: Find the smallest box based on area\n",
    "                    areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in boxes]\n",
    "                    smallest_box = boxes[np.argmin(areas)]\n",
    "    \n",
    "                    x1, y1, x2, y2 = [int(coord) for coord in smallest_box]\n",
    "                    cropped_face = frame_rgb[y1:y2, x1:x2]\n",
    "                    cropped_face_pil = Image.fromarray(cropped_face)\n",
    "    \n",
    "                    # Step 6: Crop the face from the frame\n",
    "                    faces = mtcnn(cropped_face_pil)\n",
    "                    if faces is not None and len(faces) > 0:\n",
    "                        faces = faces.to(device)\n",
    "                        embeddings = facenet(faces)  # Generate embeddings\n",
    "                        frame_embeddings.append(embeddings.detach().cpu().numpy())\n",
    "                        #print(\"Successful.\")\n",
    "                    else:\n",
    "                        # Append zeros if no valid face tensor detected\n",
    "                        frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "                        #print(\"Failed after cropping.\")\n",
    "                else:\n",
    "                    frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "                    #print(\"No faces detected\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Handle any exception raised by MTCNN and append zeros\n",
    "                #print(f\"Exception during face detection: {e}\")\n",
    "                frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Step 7: Release video capture\n",
    "    cap.release()\n",
    "    data = np.vstack(frame_embeddings)\n",
    "    return pd.DataFrame(data)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:25:32.906746Z",
     "start_time": "2024-11-26T14:25:32.893709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def longer_video(dir_path):\n",
    "    mp4_file_path = glob.glob(os.path.join(dir_path, \"*.mp4\"))[0]\n",
    "    mts_file_path = glob.glob(os.path.join(dir_path, \"*.MTS\"))[0]\n",
    "    # Get the duration of the video\n",
    "    with VideoFileClip(mp4_file_path) as video:\n",
    "        mp4_duration = video.duration\n",
    "        \n",
    "    with VideoFileClip(mts_file_path) as video:\n",
    "        mts_duration = video.duration\n",
    "    \n",
    "    if mp4_duration > mts_duration:\n",
    "        return re.compile(r'^Untitled \\d+\\.mp4$')\n",
    "    else:\n",
    "        return re.compile(r'^\\d{5}\\.MTS$')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:37:54.197699Z",
     "start_time": "2024-11-26T14:37:54.185660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def slice_vectors(video_path, biosignal_path, input_storage_path, boris1, boris2, boris1_storage_path, boris2_storage_path, research_center):\n",
    "    # Get the path for EDA, TEMP and HR\n",
    "    EDA_path = os.path.join(biosignal_path, 'EDA.csv')\n",
    "    TEMP_path = os.path.join(biosignal_path, 'TEMP.csv')\n",
    "    HR_path = os.path.join(biosignal_path, 'HR.csv')\n",
    "    \n",
    "    # Get only the data\n",
    "    EDA = pd.read_csv(EDA_path, skiprows = 2, header = None)\n",
    "    TEMP = pd.read_csv(TEMP_path, skiprows = 2, header = None)\n",
    "    HR = pd.read_csv(HR_path, skiprows = 2, header = None)\n",
    "    frame_embeddings = extract_frame_embeddings(video_path)\n",
    "    \n",
    "    # Get the starting time and frequency\n",
    "    unix_EDA, hz_EDA = get_unix_and_hz(EDA_path)\n",
    "    unix_TEMP, hz_TEMP = get_unix_and_hz(TEMP_path)\n",
    "    unix_HR, hz_HR = get_unix_and_hz(HR_path)\n",
    "    unix_video = get_video_recording_timestamp(video_path, research_center)\n",
    "\n",
    "    # Unificate the frequencies  \n",
    "    EDA_mean = mean_of_values(trim_vector(EDA, hz_EDA), hz_EDA)\n",
    "    TEMP_mean = mean_of_values(trim_vector(TEMP, hz_TEMP), hz_TEMP)\n",
    "    HR_mean = mean_of_values(trim_vector(HR, hz_HR), hz_HR)\n",
    "\n",
    "    # Get the lengths\n",
    "    length_EDA = len(EDA_mean)\n",
    "    length_TEMP = len(TEMP_mean)\n",
    "    length_HR = len(HR_mean)\n",
    "    length_video = get_video_metadata(video_path)['duration']\n",
    "    \n",
    "    # Get the vectors of starts and ends for biosignals and video\n",
    "    starts = [unix_HR, unix_TEMP, unix_EDA, unix_video]\n",
    "    ends = [unix_HR + length_HR, unix_TEMP + length_TEMP, unix_EDA + length_EDA, unix_video + length_video]\n",
    "\n",
    "    # Get the latest start of any vector\n",
    "    last_start = max(starts)\n",
    "    \n",
    "    # Get the earliest end of any vector\n",
    "    first_end = min(ends)\n",
    "\n",
    "    # Get matching indexes for start and end for every vector\n",
    "    EDA_first_index = last_start - unix_EDA\n",
    "    EDA_last_index = first_end - unix_EDA\n",
    "    TEMP_first_index = last_start - unix_TEMP\n",
    "    TEMP_last_index = first_end - unix_TEMP\n",
    "    HR_first_index = last_start - unix_HR\n",
    "    HR_last_index = first_end - unix_HR\n",
    "    video_first_index = last_start - unix_video\n",
    "    video_last_index = first_end - unix_video\n",
    "\n",
    "    print('EDA: ', EDA_last_index - EDA_first_index)\n",
    "    print('TEMP: ', TEMP_last_index - TEMP_first_index)\n",
    "    print('HR: ', HR_last_index - HR_first_index)\n",
    "    print('video: ', video_last_index - video_first_index)\n",
    "    \n",
    "    # Slice the biosignals based on the index\n",
    "    sliced_EDA = EDA[EDA_first_index:EDA_last_index]\n",
    "    sliced_TEMP = TEMP[TEMP_first_index:TEMP_last_index]\n",
    "    sliced_HR = HR[HR_first_index:HR_last_index]\n",
    "    sliced_boris_1 = boris1[video_first_index:video_last_index].copy() # to surpass the warning of working on a view and not a copy\n",
    "    sliced_boris_2 = boris2[video_first_index:video_last_index].copy() # to surpass the warning of working on a view and not a copy\n",
    "    sliced_frame_embeddings = frame_embeddings[video_first_index:video_last_index]\n",
    "    \n",
    "    # Create one df with all biosignals\n",
    "    input = pd.concat([sliced_EDA.reset_index(drop=True), sliced_TEMP.reset_index(drop=True), sliced_HR.reset_index(drop=True), sliced_frame_embeddings.reset_index()], axis=1)\n",
    "    \n",
    "    # Rename column names\n",
    "    new_columns = ['EDA', 'TEMP', 'HR'] + input.columns[3:].tolist()\n",
    "    input.columns = new_columns\n",
    "    input = input.drop(input.columns[3], axis=1)\n",
    "    # Drop index and contempt from BORIS\n",
    "    sliced_boris_1.drop([sliced_boris_1.columns[0]], axis=1, inplace=True)\n",
    "    sliced_boris_2.drop([sliced_boris_2.columns[0], sliced_boris_2.columns[1]], axis=1, inplace=True)\n",
    "    sliced_boris_2.columns = ['Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "    # Add the biosignals to file\n",
    "    input.to_csv(input_storage_path, index=False, sep=',')\n",
    "    sliced_boris_1.to_csv(boris1_storage_path, index=False, sep=',')\n",
    "    sliced_boris_2.to_csv(boris2_storage_path, index=False, sep=',')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T14:45:48.199200Z",
     "start_time": "2024-11-26T14:37:55.659298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def traverse():\n",
    "    root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE'\n",
    "    target_root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis'\n",
    "    boris_ext = 'Analysis/BORIS/'\n",
    "    type = ['Camera', 'Wristband']\n",
    "    research_centers = ['GUT', 'ITU-YU', 'MAAP']\n",
    "    s_values = [\"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\", \"S11\"]\n",
    "    c_values = [\"C01\", \"C02\", \"C03\", \"C04\", \"C05\", \"C06\", \"C07\", \"C08\", \"C09\", \"C10\", \"C11\", \"C12\", \"C13\"]\n",
    "    \n",
    "    for research_center in research_centers:\n",
    "        for session in s_values:\n",
    "            # Create the session path for biosignal and camera + BORIS\n",
    "            camera_path = Path(root_dir).joinpath(type[0], research_center, session)\n",
    "            signals_path = Path(root_dir).joinpath(type[1], research_center, session)\n",
    "            if camera_path.is_dir() and signals_path.is_dir():\n",
    "                # Create the meeting path for biosignal and camera + BORIS\n",
    "                for camera in c_values:\n",
    "                    exact_camera_path = Path(camera_path).joinpath(camera)\n",
    "                    exact_signals_path = Path(signals_path).joinpath(camera)\n",
    "                    if exact_camera_path.is_dir() and exact_signals_path.is_dir():\n",
    "                        boris_path = Path(exact_camera_path).joinpath(boris_ext)\n",
    "                        if boris_path.is_dir():\n",
    "                            # Quick fix of two MAAP sessions being divided TODO: Fix this\n",
    "                            if not(research_center == 'MAAP' and ((session == 'S01' and camera == 'C05') or (session == 'S03' and camera == 'C05'))):\n",
    "                                mp4_pattern = []\n",
    "                                if research_center == 'GUT':\n",
    "                                    video = longer_video(exact_camera_path)\n",
    "                                    mp4_pattern.append(video)\n",
    "                                elif research_center == 'ITU-YU':\n",
    "                                    mp4_pattern.append(re.compile(r'^ITU-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.mp4$'))\n",
    "                                elif research_center == 'MAAP':\n",
    "                                    mp4_pattern.append(re.compile(r'^MAAP-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.AVI$'))\n",
    "                                    mp4_pattern.append(re.compile(r'^MAAP-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.MOV$'))\n",
    "                                for files_in_camera_dir in os.listdir(exact_camera_path):\n",
    "                                    if any(pattern.match(files_in_camera_dir) for pattern in mp4_pattern):\n",
    "                                        video_path = os.path.join(exact_camera_path, files_in_camera_dir)\n",
    "                                # TODO: TRY EXCEPT FOR not matching pattern, skip iteration\n",
    "                                filename = research_center + '_' + session + '_' + camera\n",
    "                                boris1_filename = filename + '_BORIS_method_I.csv'\n",
    "                                boris2_filename = filename + '_BORIS_method_II.csv'\n",
    "                                boris1_target_dir = Path(target_root_dir).joinpath(research_center, boris1_filename)\n",
    "                                boris2_target_dir = Path(target_root_dir).joinpath(research_center, boris2_filename)\n",
    "                                input_filename = filename + '_input.csv'\n",
    "                                input_target_dir = Path(target_root_dir).joinpath(research_center, input_filename)\n",
    "                                # Create combined BORIS vector\n",
    "                                boris1, boris2 = get_boris_vectors(boris_path)\n",
    "                                # Create one vector of biosignals, sliced BORIS and sliced video\n",
    "                                slice_vectors(video_path, exact_signals_path, input_target_dir, boris1, boris2, boris1_target_dir, boris2_target_dir, research_center)\n",
    "traverse()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1\n",
      "0      0  None\n",
      "1      1  None\n",
      "2      2  None\n",
      "3      3  None\n",
      "4      4  None\n",
      "..   ...   ...\n",
      "645  645  None\n",
      "646  646  None\n",
      "647  647  None\n",
      "648  648  None\n",
      "649  649  None\n",
      "\n",
      "[650 rows x 2 columns]\n",
      "       0    1    2    3    4    5    6    7\n",
      "0      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...\n",
      "645  645  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "646  646  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "647  647  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "648  648  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "649  649  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[650 rows x 8 columns]\n",
      "Video opened successfully!\n",
      "EDA:  595\n",
      "TEMP:  595\n",
      "HR:  595\n",
      "video:  595\n",
      "       0     1\n",
      "0      0  None\n",
      "1      1  None\n",
      "2      2  None\n",
      "3      3  None\n",
      "4      4  None\n",
      "..   ...   ...\n",
      "555  555  None\n",
      "556  556  None\n",
      "557  557  None\n",
      "558  558  None\n",
      "559  559  None\n",
      "\n",
      "[560 rows x 2 columns]\n",
      "       0    1    2    3    4    5    6    7\n",
      "0      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2      2  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3      3  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4      4  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...\n",
      "555  555  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "556  556  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "557  557  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "558  558  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "559  559  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[560 rows x 8 columns]\n",
      "Video opened successfully!\n",
      "EDA:  470\n",
      "TEMP:  470\n",
      "HR:  470\n",
      "video:  470\n",
      "       0      1\n",
      "0      0   None\n",
      "1      1   None\n",
      "2      2  Happy\n",
      "3      3  Happy\n",
      "4      4  Happy\n",
      "..   ...    ...\n",
      "610  610  Happy\n",
      "611  611   None\n",
      "612  612   None\n",
      "613  613   None\n",
      "614  614   None\n",
      "\n",
      "[615 rows x 2 columns]\n",
      "       0    1       2    3    4    5    6    7\n",
      "0      0  0.0    0.00  0.0  0.0  0.0  0.0  0.0\n",
      "1      1  0.0    0.00  0.0  0.0  0.0  0.0  0.0\n",
      "2      2  0.0   66.67  0.0  0.0  0.0  0.0  0.0\n",
      "3      3  0.0  100.00  0.0  0.0  0.0  0.0  0.0\n",
      "4      4  0.0  100.00  0.0  0.0  0.0  0.0  0.0\n",
      "..   ...  ...     ...  ...  ...  ...  ...  ...\n",
      "610  610  0.0   66.67  0.0  0.0  0.0  0.0  0.0\n",
      "611  611  0.0   33.33  0.0  0.0  0.0  0.0  0.0\n",
      "612  612  0.0   33.33  0.0  0.0  0.0  0.0  0.0\n",
      "613  613  0.0    0.00  0.0  0.0  0.0  0.0  0.0\n",
      "614  614  0.0    0.00  0.0  0.0  0.0  0.0  0.0\n",
      "\n",
      "[615 rows x 8 columns]\n",
      "Video opened successfully!\n",
      "EDA:  561\n",
      "TEMP:  561\n",
      "HR:  561\n",
      "video:  561\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
