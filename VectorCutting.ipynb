{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.610259Z",
     "start_time": "2024-11-02T15:41:23.605715Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, os, re, time, logging, cv2, torch\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip\n",
    "import pytz\n",
    "import datetime\n",
    "from win32com.propsys import propsys, pscon\n",
    "import subprocess\n",
    "import json\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.662301Z",
     "start_time": "2024-11-02T15:41:23.658875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set logging level to DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Replace 'video.mp4' with the path to your media file\n",
    "#probe = ffmpeg.probe('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/Camera/GUT/S01/C02/Untitled 140.mp4')\n",
    "#print(probe)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": [
    "PYCHARM_DEBUG=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.731183Z",
     "start_time": "2024-11-02T15:41:23.726476Z"
    }
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.761639Z",
     "start_time": "2024-11-02T15:41:23.750214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_table(table):\n",
    "    for row in table:\n",
    "        print(row)\n",
    "\n",
    "def create_table(tab1, tab2, tab3):\n",
    "    result_tab = []\n",
    "\n",
    "    emotions = ['Unknown', 'Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "\n",
    "    for row1, row2, row3 in zip(tab1, tab2, tab3):\n",
    "        sum_rows = [int(a) + int(b) + int(c) for a, b, c in zip(row1[1:], row2[1:], row3[1:])]\n",
    "\n",
    "        total_sum = sum(sum_rows)\n",
    "        if total_sum > 0:\n",
    "            # Calculate the percentage distribution\n",
    "            percentages = [round((x / total_sum) * 100, 2) for x in sum_rows]\n",
    "        else:\n",
    "            percentages = [0] * len(sum_rows)\n",
    "\n",
    "        result_tab.append([row1[0]] + percentages)\n",
    "\n",
    "    return result_tab\n",
    "\n",
    "# Makes table equal\n",
    "def fill_table(table, csvreader):\n",
    "    seconds = 0\n",
    "    stop = 0\n",
    "    for row in csvreader:\n",
    "        row[0] = int(row[0].split('.')[0])\n",
    "        if seconds <= row[0] and stop == 0:  #fill table with missing seconds\n",
    "            for i in range(0, row[0]):\n",
    "                table.append([i, '0', '0', '0', '0', '0', '0', '0'])\n",
    "                seconds += 1\n",
    "            stop = 1\n",
    "            table.append(row)\n",
    "        else:\n",
    "            table.append(row)\n",
    "\n",
    "\n",
    "# Create percentages for every second\n",
    "def csv_files_reader(base_path):\n",
    "    index = ['I', 'II', 'III']\n",
    "    tab1 = []\n",
    "    tab2 = []\n",
    "    tab3 = []\n",
    "\n",
    "    if os.path.exists(base_path):\n",
    "\n",
    "        for i in index:\n",
    "            file = os.path.join(base_path, i)\n",
    "            for file_name in os.listdir(file):\n",
    "                file_path = os.path.join(file, file_name)\n",
    "\n",
    "                with open(file_path, 'r') as file:\n",
    "                    csvreader = csv.reader(file)\n",
    "                    header = next(csvreader)\n",
    "\n",
    "                    if i == 'I':\n",
    "                        fill_table(tab1, csvreader)\n",
    "                    elif i == 'II':\n",
    "                        fill_table(tab2, csvreader)\n",
    "                    elif i == 'III':\n",
    "                        fill_table(tab3, csvreader)\n",
    "    else:\n",
    "        print(f\"File path {base_path} doesn't exist.\")\n",
    "\n",
    "    large_table = max([tab1, tab2, tab3], key=len)\n",
    "\n",
    "    for tab in [tab1, tab2, tab3]:\n",
    "        if len(tab) < len(large_table):\n",
    "            diff = len(large_table) - len(tab)\n",
    "\n",
    "            if len(tab) == 0:\n",
    "                sec = 0\n",
    "                for sec in range(len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "            else:\n",
    "                sec = tab[-1][0]  #latest second in table\n",
    "                for sec in range(tab[-1][0] + 1, len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "\n",
    "    return create_table(tab1, tab2, tab3)\n",
    "\n",
    "\n",
    "def get_boris_vector(path):\n",
    "    table = csv_files_reader(path)\n",
    "    df = pd.DataFrame(table)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "def get_video_metadata(file_path):\n",
    "    try:\n",
    "        # Get the file status\n",
    "        file_stat = os.stat(file_path)\n",
    "\n",
    "        # Get the last modified time\n",
    "        last_modified_time_str = time.ctime(file_stat.st_mtime)\n",
    "        last_modified_timestamp = int(file_stat.st_mtime)\n",
    "\n",
    "        # Get the duration of the video\n",
    "        with VideoFileClip(file_path) as video:\n",
    "            duration = video.duration\n",
    "\n",
    "        metadata = {\n",
    "            'last_modified_time': last_modified_time_str,\n",
    "            'last_modified_timestamp': last_modified_timestamp,\n",
    "            'duration': int(duration),  # Duration in seconds\n",
    "            'initial_timestamp' : last_modified_timestamp - int(duration)\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return f\"The file {file_path} does not exist.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.785927Z",
     "start_time": "2024-11-02T15:41:23.779677Z"
    }
   },
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.802635Z",
     "start_time": "2024-11-02T15:41:23.798937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gut_timestamp(video_path):\n",
    "    return get_video_metadata(video_path)['initial_timestamp']"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.831698Z",
     "start_time": "2024-11-02T15:41:23.827700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ituyu_timestamp(video_path):\n",
    "    try:\n",
    "        properties = propsys.SHGetPropertyStoreFromParsingName(video_path)\n",
    "        timestamp = int(properties.GetValue(pscon.PKEY_Media_DateEncoded).GetValue().timestamp())\n",
    "        return timestamp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving video metadata: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:26:40.455671Z",
     "start_time": "2024-11-03T13:26:40.443645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def maap_timestamp(video_path):\n",
    "    try:\n",
    "        # Use ffprobe to extract video metadata\n",
    "        result = subprocess.run(\n",
    "            ['ffprobe.exe', '-v', 'quiet', '-print_format', 'json', '-show_entries', 'format_tags=creation_time', video_path],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            universal_newlines=True\n",
    "        )\n",
    "        metadata = json.loads(result.stdout)\n",
    "        \n",
    "        # Extract the creation time if available\n",
    "        creation_time = metadata.get('format', {}).get('tags', {}).get('creation_time', None)\n",
    "        \n",
    "        if creation_time:\n",
    "            creation_datetime = datetime.fromisoformat(creation_time.replace('Z', '+00:00'))\n",
    "            unix_timestamp = int(creation_datetime.timestamp())\n",
    "            return unix_timestamp\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving video metadata: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.887096Z",
     "start_time": "2024-11-02T15:41:23.882476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_video_recording_timestamp(video_path, research_center):\n",
    "    timestamp = 0\n",
    "    if research_center == 'GUT':\n",
    "        timestamp = gut_timestamp(video_path)\n",
    "    elif research_center == 'ITU-YU':\n",
    "        timestamp = ituyu_timestamp(video_path)\n",
    "    elif research_center == 'MAAP':\n",
    "        timestamp = maap_timestamp(video_path)\n",
    "    return timestamp"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the moment of the start of the vector and its frequency\n",
    "def get_unix_and_hz(file_path):\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        unix = int(float(next(reader)[0]))  # Convert the first cell to integer\n",
    "        hz = int(float(next(reader)[0]))  # Convert the second cell to integer\n",
    "    return unix, hz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.908234Z",
     "start_time": "2024-11-02T15:41:23.903109Z"
    }
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "source": [
    "# Trim the vector to be the multiple of its frequency\n",
    "def trim_vector(vector, rate):\n",
    "    length = len(vector)\n",
    "    if length % rate != 0:\n",
    "        # Calculate how many elements need to be removed\n",
    "        excess_elements = length % rate\n",
    "        # Trim the vector\n",
    "        vector = vector[:-excess_elements]\n",
    "    return vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.921294Z",
     "start_time": "2024-11-02T15:41:23.916750Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "# Change the frequency by averaging the values\n",
    "def mean_of_values(vector, rate):\n",
    "    # Ensure the length of the vector is a multiple of n\n",
    "    if len(vector) % rate != 0:\n",
    "        raise ValueError(\"Length of the vector must be a multiple of frequency\")\n",
    "\n",
    "    # Reshape the vector into a 2D array where each row is a group of n elements\n",
    "    reshaped_vector = np.reshape(vector, (-1, rate))\n",
    "\n",
    "    # Calculate the mean along the rows\n",
    "    mean_values = np.mean(reshaped_vector, axis=1)\n",
    "\n",
    "    return mean_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.937948Z",
     "start_time": "2024-11-02T15:41:23.933301Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.952749Z",
     "start_time": "2024-11-02T15:41:23.939961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_frame_embeddings(path):\n",
    "    # Step 1: Initialize FaceNet model and MTCNN detector\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)  # MTCNN for face detection\n",
    "    facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)  # Pre-trained FaceNet model\n",
    "    \n",
    "    # Step 2: Load video file and get frame rate\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    else:\n",
    "        print(\"Video opened successfully!\")\n",
    "\n",
    "    # Calculate frames per second (fps) and total frames\n",
    "    frame_interval = cap.get(cv2.CAP_PROP_FPS)  # Frames per second of the video\n",
    "\n",
    "    # Step 3: Process video at 1 second intervals\n",
    "    frame_count = 0\n",
    "    frame_embeddings = []\n",
    "    num_of_features = 512\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Check if the frame is at the 1-second interval\n",
    "        if frame_count % frame_interval < 1:\n",
    "            # Convert frame to RGB (OpenCV uses BGR by default)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            try:\n",
    "                # Step 4: Detect faces in the frame\n",
    "                boxes, _ = mtcnn.detect(frame_pil)\n",
    "                if boxes is not None and len(boxes) > 0:\n",
    "                    # Step 5: Find the smallest box based on area\n",
    "                    areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in boxes]\n",
    "                    smallest_box = boxes[np.argmin(areas)]\n",
    "    \n",
    "                    x1, y1, x2, y2 = [int(coord) for coord in smallest_box]\n",
    "                    cropped_face = frame_rgb[y1:y2, x1:x2]\n",
    "                    cropped_face_pil = Image.fromarray(cropped_face)\n",
    "    \n",
    "                    # Step 6: Crop the face from the frame\n",
    "                    faces = mtcnn(cropped_face_pil)\n",
    "                    if faces is not None and len(faces) > 0:\n",
    "                        faces = faces.to(device)\n",
    "                        embeddings = facenet(faces)  # Generate embeddings\n",
    "                        frame_embeddings.append(embeddings.detach().cpu().numpy())\n",
    "                        #print(\"Successful.\")\n",
    "                    else:\n",
    "                        # Append zeros if no valid face tensor detected\n",
    "                        frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "                        #print(\"Failed after cropping.\")\n",
    "                else:\n",
    "                    frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "                    #print(\"No faces detected\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Handle any exception raised by MTCNN and append zeros\n",
    "                #print(f\"Exception during face detection: {e}\")\n",
    "                frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Step 7: Release video capture\n",
    "    cap.release()\n",
    "    data = np.vstack(frame_embeddings)\n",
    "    return pd.DataFrame(data)"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T15:41:23.985339Z",
     "start_time": "2024-11-02T15:41:23.974760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def slice_vectors(video_path, biosignal_path, input_storage_path, boris, boris_storage_path, research_center):\n",
    "    # Get the path for EDA, TEMP and HR\n",
    "    EDA_path = os.path.join(biosignal_path, 'EDA.csv')\n",
    "    TEMP_path = os.path.join(biosignal_path, 'TEMP.csv')\n",
    "    HR_path = os.path.join(biosignal_path, 'HR.csv')\n",
    "    \n",
    "    # Get only the data\n",
    "    EDA = pd.read_csv(EDA_path, skiprows = 2, header = None)\n",
    "    TEMP = pd.read_csv(TEMP_path, skiprows = 2, header = None)\n",
    "    HR = pd.read_csv(HR_path, skiprows = 2, header = None)\n",
    "    frame_embeddings = extract_frame_embeddings(video_path)\n",
    "    \n",
    "    # Get the starting time and frequency\n",
    "    unix_EDA, hz_EDA = get_unix_and_hz(EDA_path)\n",
    "    unix_TEMP, hz_TEMP = get_unix_and_hz(TEMP_path)\n",
    "    unix_HR, hz_HR = get_unix_and_hz(HR_path)\n",
    "    unix_video = get_video_recording_timestamp(video_path, research_center)\n",
    "\n",
    "    # Unificate the frequencies  \n",
    "    EDA_mean = mean_of_values(trim_vector(EDA, hz_EDA), hz_EDA)\n",
    "    TEMP_mean = mean_of_values(trim_vector(TEMP, hz_TEMP), hz_TEMP)\n",
    "    HR_mean = mean_of_values(trim_vector(HR, hz_HR), hz_HR)\n",
    "\n",
    "    # Get the lengths\n",
    "    length_EDA = len(EDA_mean)\n",
    "    length_TEMP = len(TEMP_mean)\n",
    "    length_HR = len(HR_mean)\n",
    "    length_video = get_video_metadata(video_path)['duration']\n",
    "    \n",
    "    # Get the vectors of starts and ends for biosignals and video\n",
    "    starts = [unix_HR, unix_TEMP, unix_EDA, unix_video]\n",
    "    ends = [unix_HR + length_HR, unix_TEMP + length_TEMP, unix_EDA + length_EDA, unix_video + length_video]\n",
    "\n",
    "    # Get the latest start of any vector\n",
    "    last_start = max(starts)\n",
    "    \n",
    "    # Get the earliest end of any vector\n",
    "    first_end = min(ends)\n",
    "\n",
    "    # Get matching indexes for start and end for every vector\n",
    "    EDA_first_index = last_start - unix_EDA\n",
    "    EDA_last_index = first_end - unix_EDA\n",
    "    TEMP_first_index = last_start - unix_TEMP\n",
    "    TEMP_last_index = first_end - unix_TEMP\n",
    "    HR_first_index = last_start - unix_HR\n",
    "    HR_last_index = first_end - unix_HR\n",
    "    video_first_index = last_start - unix_video\n",
    "    video_last_index = first_end - unix_video\n",
    "\n",
    "    print('EDA: ', EDA_last_index - EDA_first_index)\n",
    "    print('TEMP: ', TEMP_last_index - TEMP_first_index)\n",
    "    print('HR: ', HR_last_index - HR_first_index)\n",
    "    print('video: ', video_last_index - video_first_index)\n",
    "    \n",
    "    # Slice the biosignals based on the index\n",
    "    sliced_EDA = EDA[EDA_first_index:EDA_last_index]\n",
    "    sliced_TEMP = TEMP[TEMP_first_index:TEMP_last_index]\n",
    "    sliced_HR = HR[HR_first_index:HR_last_index]\n",
    "    sliced_boris = boris[video_first_index:video_last_index].copy() # to surpass the warning of working on a view and not a copy\n",
    "    sliced_frame_embeddings = frame_embeddings[video_first_index:video_last_index]\n",
    "    \n",
    "    # Create one df with all biosignals\n",
    "    input = pd.concat([sliced_EDA.reset_index(drop=True), sliced_TEMP.reset_index(drop=True), sliced_HR.reset_index(drop=True), sliced_frame_embeddings.reset_index()], axis=1)\n",
    "    \n",
    "    # Rename column names\n",
    "    new_columns = ['EDA', 'TEMP', 'HR'] + input.columns[3:].tolist()\n",
    "    input.columns = new_columns\n",
    "    input = input.drop(input.columns[3], axis=1)\n",
    "    # Drop index and contempt from BORIS\n",
    "    sliced_boris.drop([sliced_boris.columns[0], sliced_boris.columns[1]], axis=1, inplace=True)\n",
    "    sliced_boris.columns = ['Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "    # Add the biosignals to file\n",
    "    input.to_csv(input_storage_path, index=False, sep=',')\n",
    "    sliced_boris.to_csv(boris_storage_path, index=False, sep=',')"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T16:34:21.765591Z",
     "start_time": "2024-11-03T13:52:52.488212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def traverse():\n",
    "    root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE'\n",
    "    target_root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis'\n",
    "    boris_ext = 'Analysis/BORIS/'\n",
    "    type = ['Camera', 'Wristband']\n",
    "    research_centers = ['MAAP']\n",
    "    #research_centers = ['GUT', 'ITU-YU', 'MAAP']\n",
    "    #s_values = [\"S02\"]\n",
    "    s_values = [\"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\", \"S11\" ]\n",
    "    #c_values = [\"C03\"]\n",
    "    c_values = [\"C01\", \"C02\", \"C03\", \"C04\", \"C05\", \"C06\", \"C07\", \"C08\", \"C09\", \"C10\", \"C11\", \"C12\", \"C13\" ]\n",
    "    for research_center in research_centers:\n",
    "        for session in s_values:\n",
    "            # Create the session path for biosignal and camera + BORIS\n",
    "            camera_path = Path(root_dir).joinpath(type[0], research_center, session)\n",
    "            signals_path = Path(root_dir).joinpath(type[1], research_center, session)\n",
    "            if camera_path.is_dir() and signals_path.is_dir():\n",
    "                # Create the meeting path for biosignal and camera + BORIS\n",
    "                for camera in c_values:\n",
    "                    exact_camera_path = Path(camera_path).joinpath(camera)\n",
    "                    exact_signals_path = Path(signals_path).joinpath(camera)\n",
    "                    if exact_camera_path.is_dir() and exact_signals_path.is_dir():\n",
    "                        boris_path = Path(exact_camera_path).joinpath(boris_ext)\n",
    "                        if boris_path.is_dir():\n",
    "                            # Quick fix of two MAAP sessions being divided TODO: Fix this\n",
    "                            if not(research_center == 'MAAP' and ((session == 'S01' and camera == 'C05') or (session == 'S03' and camera == 'C05'))):\n",
    "                                mp4_pattern = []\n",
    "                                if research_center == 'GUT':\n",
    "                                    mp4_pattern.append(re.compile(r'^Untitled \\d+\\.mp4$'))\n",
    "                                elif research_center == 'ITU-YU':\n",
    "                                    mp4_pattern.append(re.compile(r'^ITU-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.mp4$'))\n",
    "                                elif research_center == 'MAAP':\n",
    "                                    mp4_pattern.append(re.compile(r'^MAAP-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.AVI$'))\n",
    "                                    mp4_pattern.append(re.compile(r'^MAAP-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.MOV$'))\n",
    "                                for files_in_camera_dir in os.listdir(exact_camera_path):\n",
    "                                    if any(pattern.match(files_in_camera_dir) for pattern in mp4_pattern):\n",
    "                                        video_path = os.path.join(exact_camera_path, files_in_camera_dir)\n",
    "                                # TODO: TRY EXCEPT FOR not matching pattern, skip iteration\n",
    "                                filename = research_center + '_' + session + '_' + camera\n",
    "                                boris_filename = filename + '_BORIS.csv'\n",
    "                                boris_target_dir = Path(target_root_dir).joinpath(research_center, boris_filename)\n",
    "                                \n",
    "                                input_filename = filename + '_input.csv'\n",
    "                                input_target_dir = Path(target_root_dir).joinpath(research_center, input_filename)\n",
    "                                # Create combined BORIS vector\n",
    "                                boris = get_boris_vector(boris_path)\n",
    "                                # Create one vector of biosignals, sliced BORIS and sliced video\n",
    "                                slice_vectors(video_path, exact_signals_path, input_target_dir, boris, boris_target_dir, research_center)\n",
    "traverse()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video opened successfully!\n",
      "EDA:  807\n",
      "TEMP:  807\n",
      "HR:  807\n",
      "video:  807\n",
      "Video opened successfully!\n",
      "EDA:  191\n",
      "TEMP:  191\n",
      "HR:  191\n",
      "video:  191\n",
      "Video opened successfully!\n",
      "EDA:  891\n",
      "TEMP:  891\n",
      "HR:  891\n",
      "video:  891\n",
      "Video opened successfully!\n",
      "EDA:  506\n",
      "TEMP:  506\n",
      "HR:  506\n",
      "video:  506\n",
      "Video opened successfully!\n",
      "EDA:  566\n",
      "TEMP:  566\n",
      "HR:  566\n",
      "video:  566\n",
      "Video opened successfully!\n",
      "EDA:  94\n",
      "TEMP:  94\n",
      "HR:  94\n",
      "video:  94\n",
      "Video opened successfully!\n",
      "EDA:  486\n",
      "TEMP:  486\n",
      "HR:  486\n",
      "video:  486\n",
      "Video opened successfully!\n",
      "EDA:  471\n",
      "TEMP:  471\n",
      "HR:  471\n",
      "video:  471\n",
      "Video opened successfully!\n",
      "EDA:  152\n",
      "TEMP:  152\n",
      "HR:  152\n",
      "video:  152\n",
      "Video opened successfully!\n",
      "EDA:  546\n",
      "TEMP:  546\n",
      "HR:  546\n",
      "video:  546\n",
      "Video opened successfully!\n",
      "EDA:  331\n",
      "TEMP:  331\n",
      "HR:  331\n",
      "video:  331\n",
      "Video opened successfully!\n",
      "EDA:  469\n",
      "TEMP:  469\n",
      "HR:  469\n",
      "video:  469\n",
      "Video opened successfully!\n",
      "EDA:  675\n",
      "TEMP:  675\n",
      "HR:  675\n",
      "video:  675\n",
      "Video opened successfully!\n",
      "EDA:  656\n",
      "TEMP:  656\n",
      "HR:  656\n",
      "video:  656\n",
      "Video opened successfully!\n",
      "EDA:  637\n",
      "TEMP:  637\n",
      "HR:  637\n",
      "video:  637\n",
      "Video opened successfully!\n",
      "EDA:  585\n",
      "TEMP:  585\n",
      "HR:  585\n",
      "video:  585\n",
      "Video opened successfully!\n",
      "EDA:  547\n",
      "TEMP:  547\n",
      "HR:  547\n",
      "video:  547\n",
      "Video opened successfully!\n",
      "EDA:  317\n",
      "TEMP:  317\n",
      "HR:  317\n",
      "video:  317\n",
      "Video opened successfully!\n",
      "EDA:  247\n",
      "TEMP:  247\n",
      "HR:  247\n",
      "video:  247\n",
      "Video opened successfully!\n",
      "EDA:  595\n",
      "TEMP:  595\n",
      "HR:  595\n",
      "video:  595\n",
      "Video opened successfully!\n",
      "EDA:  390\n",
      "TEMP:  390\n",
      "HR:  390\n",
      "video:  390\n",
      "Video opened successfully!\n",
      "EDA:  353\n",
      "TEMP:  353\n",
      "HR:  353\n",
      "video:  353\n",
      "Video opened successfully!\n",
      "EDA:  401\n",
      "TEMP:  401\n",
      "HR:  401\n",
      "video:  401\n",
      "Video opened successfully!\n",
      "EDA:  671\n",
      "TEMP:  671\n",
      "HR:  671\n",
      "video:  671\n",
      "Video opened successfully!\n",
      "EDA:  617\n",
      "TEMP:  617\n",
      "HR:  617\n",
      "video:  617\n",
      "Video opened successfully!\n",
      "EDA:  374\n",
      "TEMP:  374\n",
      "HR:  374\n",
      "video:  374\n",
      "Video opened successfully!\n",
      "EDA:  470\n",
      "TEMP:  470\n",
      "HR:  470\n",
      "video:  470\n",
      "Video opened successfully!\n",
      "EDA:  461\n",
      "TEMP:  461\n",
      "HR:  461\n",
      "video:  461\n",
      "Video opened successfully!\n",
      "EDA:  445\n",
      "TEMP:  445\n",
      "HR:  445\n",
      "video:  445\n",
      "Video opened successfully!\n",
      "EDA:  567\n",
      "TEMP:  567\n",
      "HR:  567\n",
      "video:  567\n",
      "Video opened successfully!\n",
      "EDA:  619\n",
      "TEMP:  619\n",
      "HR:  619\n",
      "video:  619\n",
      "Video opened successfully!\n",
      "EDA:  703\n",
      "TEMP:  703\n",
      "HR:  703\n",
      "video:  703\n",
      "Video opened successfully!\n",
      "EDA:  715\n",
      "TEMP:  715\n",
      "HR:  715\n",
      "video:  715\n",
      "Video opened successfully!\n",
      "EDA:  552\n",
      "TEMP:  552\n",
      "HR:  552\n",
      "video:  552\n",
      "Video opened successfully!\n",
      "EDA:  340\n",
      "TEMP:  340\n",
      "HR:  340\n",
      "video:  340\n",
      "Video opened successfully!\n",
      "EDA:  503\n",
      "TEMP:  503\n",
      "HR:  503\n",
      "video:  503\n",
      "Video opened successfully!\n",
      "EDA:  589\n",
      "TEMP:  589\n",
      "HR:  589\n",
      "video:  589\n",
      "Video opened successfully!\n",
      "EDA:  631\n",
      "TEMP:  631\n",
      "HR:  631\n",
      "video:  631\n",
      "Video opened successfully!\n",
      "EDA:  620\n",
      "TEMP:  620\n",
      "HR:  620\n",
      "video:  620\n",
      "Video opened successfully!\n",
      "EDA:  351\n",
      "TEMP:  351\n",
      "HR:  351\n",
      "video:  351\n",
      "Video opened successfully!\n",
      "EDA:  755\n",
      "TEMP:  755\n",
      "HR:  755\n",
      "video:  755\n",
      "Video opened successfully!\n",
      "EDA:  386\n",
      "TEMP:  386\n",
      "HR:  386\n",
      "video:  386\n",
      "Video opened successfully!\n",
      "EDA:  484\n",
      "TEMP:  484\n",
      "HR:  484\n",
      "video:  484\n",
      "Video opened successfully!\n",
      "EDA:  598\n",
      "TEMP:  598\n",
      "HR:  598\n",
      "video:  598\n",
      "Video opened successfully!\n",
      "EDA:  421\n",
      "TEMP:  421\n",
      "HR:  421\n",
      "video:  421\n",
      "Video opened successfully!\n",
      "EDA:  633\n",
      "TEMP:  633\n",
      "HR:  633\n",
      "video:  633\n",
      "Video opened successfully!\n",
      "EDA:  745\n",
      "TEMP:  745\n",
      "HR:  745\n",
      "video:  745\n",
      "Video opened successfully!\n",
      "EDA:  590\n",
      "TEMP:  590\n",
      "HR:  590\n",
      "video:  590\n",
      "Video opened successfully!\n",
      "EDA:  567\n",
      "TEMP:  567\n",
      "HR:  567\n",
      "video:  567\n",
      "Video opened successfully!\n",
      "EDA:  691\n",
      "TEMP:  691\n",
      "HR:  691\n",
      "video:  691\n",
      "Video opened successfully!\n",
      "EDA:  588\n",
      "TEMP:  588\n",
      "HR:  588\n",
      "video:  588\n",
      "Video opened successfully!\n",
      "EDA:  658\n",
      "TEMP:  658\n",
      "HR:  658\n",
      "video:  658\n",
      "Video opened successfully!\n",
      "EDA:  735\n",
      "TEMP:  735\n",
      "HR:  735\n",
      "video:  735\n",
      "Video opened successfully!\n",
      "EDA:  609\n",
      "TEMP:  609\n",
      "HR:  609\n",
      "video:  609\n",
      "Video opened successfully!\n",
      "EDA:  616\n",
      "TEMP:  616\n",
      "HR:  616\n",
      "video:  616\n",
      "Video opened successfully!\n",
      "EDA:  572\n",
      "TEMP:  572\n",
      "HR:  572\n",
      "video:  572\n",
      "Video opened successfully!\n",
      "EDA:  563\n",
      "TEMP:  563\n",
      "HR:  563\n",
      "video:  563\n",
      "Video opened successfully!\n",
      "EDA:  490\n",
      "TEMP:  490\n",
      "HR:  490\n",
      "video:  490\n",
      "Video opened successfully!\n",
      "EDA:  442\n",
      "TEMP:  442\n",
      "HR:  442\n",
      "video:  442\n",
      "Video opened successfully!\n",
      "EDA:  561\n",
      "TEMP:  561\n",
      "HR:  561\n",
      "video:  561\n",
      "Video opened successfully!\n",
      "EDA:  782\n",
      "TEMP:  782\n",
      "HR:  782\n",
      "video:  782\n",
      "Video opened successfully!\n",
      "EDA:  759\n",
      "TEMP:  759\n",
      "HR:  759\n",
      "video:  759\n",
      "Video opened successfully!\n",
      "EDA:  701\n",
      "TEMP:  701\n",
      "HR:  701\n",
      "video:  701\n",
      "Video opened successfully!\n",
      "EDA:  634\n",
      "TEMP:  634\n",
      "HR:  634\n",
      "video:  634\n",
      "Video opened successfully!\n",
      "EDA:  575\n",
      "TEMP:  575\n",
      "HR:  575\n",
      "video:  575\n",
      "Video opened successfully!\n",
      "EDA:  463\n",
      "TEMP:  463\n",
      "HR:  463\n",
      "video:  463\n",
      "Video opened successfully!\n",
      "EDA:  780\n",
      "TEMP:  780\n",
      "HR:  780\n",
      "video:  780\n",
      "Video opened successfully!\n",
      "EDA:  614\n",
      "TEMP:  614\n",
      "HR:  614\n",
      "video:  614\n",
      "Video opened successfully!\n",
      "EDA:  516\n",
      "TEMP:  516\n",
      "HR:  516\n",
      "video:  516\n",
      "Video opened successfully!\n",
      "EDA:  661\n",
      "TEMP:  661\n",
      "HR:  661\n",
      "video:  661\n",
      "Video opened successfully!\n",
      "EDA:  512\n",
      "TEMP:  512\n",
      "HR:  512\n",
      "video:  512\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
