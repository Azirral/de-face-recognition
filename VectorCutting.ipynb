{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:42.611552Z",
     "start_time": "2024-10-10T16:27:42.608297Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv, os, re, time, logging, cv2, torch\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from PIL import Image\n",
    "from moviepy.editor import VideoFileClip"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:44.156609Z",
     "start_time": "2024-10-10T16:27:44.153024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set logging level to DEBUG\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Replace 'video.mp4' with the path to your media file\n",
    "#probe = ffmpeg.probe('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/Camera/GUT/S01/C02/Untitled 140.mp4')\n",
    "#print(probe)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:44.964913Z",
     "start_time": "2024-10-10T16:27:44.881334Z"
    }
   },
   "cell_type": "code",
   "source": "version('ffmpeg-python')",
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for ffmpeg-python",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mStopIteration\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:397\u001B[0m, in \u001B[0;36mDistribution.from_name\u001B[1;34m(cls, name)\u001B[0m\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiscover\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n",
      "\u001B[1;31mStopIteration\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mPackageNotFoundError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mversion\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mffmpeg-python\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:889\u001B[0m, in \u001B[0;36mversion\u001B[1;34m(distribution_name)\u001B[0m\n\u001B[0;32m    882\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mversion\u001B[39m(distribution_name):\n\u001B[0;32m    883\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the version string for the named package.\u001B[39;00m\n\u001B[0;32m    884\u001B[0m \n\u001B[0;32m    885\u001B[0m \u001B[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001B[39;00m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;124;03m    :return: The version string for the package as defined in the package's\u001B[39;00m\n\u001B[0;32m    887\u001B[0m \u001B[38;5;124;03m        \"Version\" metadata key.\u001B[39;00m\n\u001B[0;32m    888\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 889\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdistribution\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistribution_name\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mversion\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:862\u001B[0m, in \u001B[0;36mdistribution\u001B[1;34m(distribution_name)\u001B[0m\n\u001B[0;32m    856\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdistribution\u001B[39m(distribution_name):\n\u001B[0;32m    857\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \n\u001B[0;32m    859\u001B[0m \u001B[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001B[39;00m\n\u001B[0;32m    861\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDistribution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdistribution_name\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\metadata\\__init__.py:399\u001B[0m, in \u001B[0;36mDistribution.from_name\u001B[1;34m(cls, name)\u001B[0m\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mdiscover(name\u001B[38;5;241m=\u001B[39mname))\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m--> 399\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PackageNotFoundError(name)\n",
      "\u001B[1;31mPackageNotFoundError\u001B[0m: No package metadata was found for ffmpeg-python"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "PYCHARM_DEBUG=True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:46.066005Z",
     "start_time": "2024-10-10T16:27:46.062473Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:46.862354Z",
     "start_time": "2024-10-10T16:27:46.847250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_table(table):\n",
    "    for row in table:\n",
    "        print(row)\n",
    "\n",
    "def create_table(tab1, tab2, tab3):\n",
    "    result_tab = []\n",
    "\n",
    "    emotions = ['Unknown', 'Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "\n",
    "    for row1, row2, row3 in zip(tab1, tab2, tab3):\n",
    "        sum_rows = [int(a) + int(b) + int(c) for a, b, c in zip(row1[1:], row2[1:], row3[1:])]\n",
    "\n",
    "        total_sum = sum(sum_rows)\n",
    "        if total_sum > 0:\n",
    "            # Calculate the percentage distribution\n",
    "            percentages = [round((x / total_sum) * 100, 2) for x in sum_rows]\n",
    "        else:\n",
    "            percentages = [0] * len(sum_rows)\n",
    "\n",
    "        result_tab.append([row1[0]] + percentages)\n",
    "\n",
    "    return result_tab\n",
    "\n",
    "# Makes table equal\n",
    "def fill_table(table, csvreader):\n",
    "    seconds = 0\n",
    "    stop = 0\n",
    "    for row in csvreader:\n",
    "        row[0] = int(row[0].split('.')[0])\n",
    "        if seconds <= row[0] and stop == 0:  #fill table with missing seconds\n",
    "            for i in range(0, row[0]):\n",
    "                table.append([i, '0', '0', '0', '0', '0', '0', '0'])\n",
    "                seconds += 1\n",
    "            stop = 1\n",
    "            table.append(row)\n",
    "        else:\n",
    "            table.append(row)\n",
    "\n",
    "\n",
    "# Create percentages for every second\n",
    "def csv_files_reader(base_path):\n",
    "    index = ['I', 'II', 'III']\n",
    "    tab1 = []\n",
    "    tab2 = []\n",
    "    tab3 = []\n",
    "\n",
    "    if os.path.exists(base_path):\n",
    "\n",
    "        for i in index:\n",
    "            file = os.path.join(base_path, i)\n",
    "            for file_name in os.listdir(file):\n",
    "                file_path = os.path.join(file, file_name)\n",
    "\n",
    "                with open(file_path, 'r') as file:\n",
    "                    csvreader = csv.reader(file)\n",
    "                    header = next(csvreader)\n",
    "\n",
    "                    if i == 'I':\n",
    "                        fill_table(tab1, csvreader)\n",
    "                    elif i == 'II':\n",
    "                        fill_table(tab2, csvreader)\n",
    "                    elif i == 'III':\n",
    "                        fill_table(tab3, csvreader)\n",
    "    else:\n",
    "        print(f\"File path {base_path} doesn't exist.\")\n",
    "\n",
    "    large_table = max([tab1, tab2, tab3], key=len)\n",
    "\n",
    "    for tab in [tab1, tab2, tab3]:\n",
    "        if len(tab) < len(large_table):\n",
    "            diff = len(large_table) - len(tab)\n",
    "\n",
    "            if len(tab) == 0:\n",
    "                sec = 0\n",
    "                for sec in range(len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "            else:\n",
    "                sec = tab[-1][0]  #latest second in table\n",
    "                for sec in range(tab[-1][0] + 1, len(large_table)):\n",
    "                    tab.append([sec, '0', '0', '0', '0', '0', '0', '0'])\n",
    "\n",
    "    return create_table(tab1, tab2, tab3)\n",
    "\n",
    "\n",
    "def get_boris_vector(path, target):\n",
    "    table = csv_files_reader(path)\n",
    "    df = pd.DataFrame(table)\n",
    "    df.to_csv(target, index=False)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def get_video_metadata(file_path):\n",
    "    try:\n",
    "        # Get the file status\n",
    "        file_stat = os.stat(file_path)\n",
    "\n",
    "        # Get the last modified time\n",
    "        last_modified_time_str = time.ctime(file_stat.st_mtime)\n",
    "        last_modified_timestamp = int(file_stat.st_mtime)\n",
    "\n",
    "        # Get the duration of the video\n",
    "        with VideoFileClip(file_path) as video:\n",
    "            duration = video.duration\n",
    "\n",
    "        metadata = {\n",
    "            'last_modified_time': last_modified_time_str,\n",
    "            'last_modified_timestamp': last_modified_timestamp,\n",
    "            'duration': int(duration),  # Duration in seconds\n",
    "            'initial_timestamp' : last_modified_timestamp - int(duration)\n",
    "        }\n",
    "\n",
    "        return metadata\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return f\"The file {file_path} does not exist.\"\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:48.306600Z",
     "start_time": "2024-10-10T16:27:48.295391Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the moment of the start of the vector and its frequency\n",
    "def get_unix_and_hz(file_path):\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        unix = int(float(next(reader)[0]))  # Convert the first cell to integer\n",
    "        hz = int(float(next(reader)[0]))  # Convert the second cell to integer\n",
    "    return unix, hz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:49.745756Z",
     "start_time": "2024-10-10T16:27:49.741843Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Trim the vector to be the multiple of its frequency\n",
    "def trim_vector(vector, rate):\n",
    "    length = len(vector)\n",
    "    if length % rate != 0:\n",
    "        # Calculate how many elements need to be removed\n",
    "        excess_elements = length % rate\n",
    "        # Trim the vector\n",
    "        vector = vector[:-excess_elements]\n",
    "    return vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:50.993534Z",
     "start_time": "2024-10-10T16:27:50.987379Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Change the frequency by averaging the values\n",
    "def mean_of_values(vector, rate):\n",
    "    # Ensure the length of the vector is a multiple of n\n",
    "    if len(vector) % rate != 0:\n",
    "        raise ValueError(\"Length of the vector must be a multiple of frequency\")\n",
    "\n",
    "    # Reshape the vector into a 2D array where each row is a group of n elements\n",
    "    reshaped_vector = np.reshape(vector, (-1, rate))\n",
    "\n",
    "    # Calculate the mean along the rows\n",
    "    mean_values = np.mean(reshaped_vector, axis=1)\n",
    "\n",
    "    return mean_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:52.484629Z",
     "start_time": "2024-10-10T16:27:52.481165Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:53.698068Z",
     "start_time": "2024-10-10T16:27:53.690993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_frame_embeddings(path):\n",
    "    # Step 1: Initialize FaceNet model and MTCNN detector\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    mtcnn = MTCNN(keep_all=True, device=device)  # MTCNN for face detection\n",
    "    facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)  # Pre-trained FaceNet model\n",
    "    \n",
    "    # Step 2: Load video file and get frame rate\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "    else:\n",
    "        print(\"Video opened successfully!\")\n",
    "\n",
    "    # Calculate frames per second (fps) and total frames\n",
    "    frame_interval = cap.get(cv2.CAP_PROP_FPS)  # Frames per second of the video\n",
    "\n",
    "    # Step 3: Process video at 1 second intervals\n",
    "    frame_count = 0\n",
    "    frame_embeddings = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Check if the frame is at the 1-second interval\n",
    "        if frame_count % frame_interval < 1:\n",
    "            # Convert frame to RGB (OpenCV uses BGR by default)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "\n",
    "            # Step 4: Detect faces in the frame\n",
    "            boxes, _ = mtcnn.detect(frame_pil)\n",
    "            if boxes is None:\n",
    "                num_of_features = 512\n",
    "\n",
    "                frame_embeddings.append(np.zeros(num_of_features, dtype=np.float32))\n",
    "                frame_count += 1\n",
    "                continue  # Skip frames with no detected faces\n",
    "\n",
    "            # Step 5: Crop and align each detected face\n",
    "            faces = mtcnn(frame_pil)  # This will return aligned faces\n",
    "\n",
    "            # Step 6: Generate embeddings for each face\n",
    "            if faces is not None:\n",
    "                faces = faces.to(device)\n",
    "                embeddings = facenet(faces)  # Generate embeddings\n",
    "                frame_embeddings.append(embeddings.cpu().detach().numpy())  # Store embeddings \n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    # Step 7: Release video capture\n",
    "    cap.release()\n",
    "    frame_embeddings = [frame_embeddings[0][0] for a in frame_embeddings]\n",
    "    return pd.DataFrame(frame_embeddings)\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:27:55.332304Z",
     "start_time": "2024-10-10T16:27:55.321663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def slice_vectors(video_path, biosignal_path, input_storage_path):\n",
    "    \n",
    "    # Get the video metadata\n",
    "    video = get_video_metadata(video_path)\n",
    "    print(video)\n",
    "    # Get the path for EDA, TEMP and HR\n",
    "    EDA_path = os.path.join(biosignal_path, 'EDA.csv')\n",
    "    TEMP_path = os.path.join(biosignal_path, 'TEMP.csv')\n",
    "    HR_path = os.path.join(biosignal_path, 'HR.csv')\n",
    "\n",
    "    # Get only the data\n",
    "    EDA = pd.read_csv(EDA_path, skiprows = 2, header = None)\n",
    "    TEMP = pd.read_csv(TEMP_path, skiprows = 2, header = None)\n",
    "    HR = pd.read_csv(HR_path, skiprows = 2, header = None)\n",
    "    frame_embeddings = extract_frame_embeddings(video_path)\n",
    "\n",
    "    # Get the starting time and frequency\n",
    "    unix_EDA, hz_EDA = get_unix_and_hz(EDA_path)\n",
    "    unix_TEMP, hz_TEMP = get_unix_and_hz(TEMP_path)\n",
    "    unix_HR, hz_HR = get_unix_and_hz(HR_path)\n",
    "    unix_video = video['initial_timestamp']\n",
    "\n",
    "    # Unificate the frequencies  \n",
    "    EDA_mean = mean_of_values(trim_vector(EDA, hz_EDA), hz_EDA)\n",
    "    TEMP_mean = mean_of_values(trim_vector(TEMP, hz_TEMP), hz_TEMP)\n",
    "    HR_mean = mean_of_values(trim_vector(HR, hz_HR), hz_HR)\n",
    "\n",
    "    # Get the lengths\n",
    "    length_EDA = len(EDA_mean)\n",
    "    length_TEMP = len(TEMP_mean)\n",
    "    length_HR = len(HR_mean)\n",
    "    length_video = video['duration']\n",
    "    \n",
    "    # Get the vectors of starts and ends for biosignals and video\n",
    "    starts = [unix_HR, unix_TEMP, unix_EDA, unix_video]\n",
    "    ends = [unix_HR + length_HR, unix_TEMP + length_TEMP, unix_EDA + length_EDA, unix_video + length_video]\n",
    "\n",
    "    # Get the latest start of any vector\n",
    "    last_start = max(starts)\n",
    "    \n",
    "    # Get the earliest end of any vector\n",
    "    first_end = min(ends)\n",
    "\n",
    "    # Get matching indexes for start and end for every vector\n",
    "    EDA_first_index = last_start - unix_EDA\n",
    "    EDA_last_index = first_end - unix_EDA\n",
    "    TEMP_first_index = last_start - unix_TEMP\n",
    "    TEMP_last_index = first_end - unix_TEMP\n",
    "    HR_first_index = last_start - unix_HR\n",
    "    HR_last_index = first_end - unix_HR\n",
    "    video_first_index = last_start - unix_video\n",
    "    video_last_index = first_end - unix_video\n",
    "\n",
    "\n",
    "    print('EDA: ', EDA_last_index - EDA_first_index)\n",
    "    print('TEMP: ', TEMP_last_index - TEMP_first_index)\n",
    "    print('HR: ', HR_last_index - HR_first_index)\n",
    "    print('video: ', video_last_index - video_first_index)\n",
    "    \n",
    "    # Slice the biosignals based on the index\n",
    "    sliced_EDA = EDA[EDA_first_index:EDA_last_index]\n",
    "    sliced_TEMP = TEMP[TEMP_first_index:TEMP_last_index]\n",
    "    sliced_HR = HR[HR_first_index:HR_last_index]\n",
    "    sliced_frame_embeddings = frame_embeddings[video_first_index:video_last_index]\n",
    "    \n",
    "    # Create one df with all biosignals\n",
    "    # TODO: ADD VECTOR OF EMBEDDINGS\n",
    "    input = pd.concat([sliced_EDA.reset_index(drop=True), sliced_TEMP.reset_index(drop=True), sliced_HR.reset_index(drop=True), sliced_frame_embeddings.reset_index()], axis=1)\n",
    "\n",
    "    # Rename column names\n",
    "    input.columns.values[0:3] = [\"EDA\", \"TEMP\", \"HR\"]\n",
    "    input = input.drop(input.columns[3], axis=1)\n",
    "    # Add the biosignals to file\n",
    "    input.to_csv(input_storage_path, index=False, sep=';')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T16:30:31.897623Z",
     "start_time": "2024-10-10T16:27:57.203014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def traverse():\n",
    "    root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE'\n",
    "    target_root_dir = '//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis'\n",
    "    boris_ext = 'Analysis/BORIS/'\n",
    "    type = ['Camera', 'Wristband']\n",
    "    research_centers = ['GUT']\n",
    "    #research_centers = ['GUT', 'ITU-YU', 'MAAP']\n",
    "    s_values = [\"S01\"]\n",
    "    #s_values = [\"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", \"S08\", \"S09\", \"S10\", \"S11\" ]\n",
    "    c_values = [\"C01\"]\n",
    "    #c_values = [\"C01\", \"C02\", \"C03\", \"C04\", \"C05\", \"C06\", \"C07\", \"C08\", \"C09\", \"C10\", \"C11\", \"C12\", \"C13\" ]\n",
    "    for research_center in research_centers:\n",
    "        for session in s_values:\n",
    "            # Create the session path for biosignal and camera + BORIS\n",
    "            camera_path = Path(root_dir).joinpath(type[0], research_center, session)\n",
    "            signals_path = Path(root_dir).joinpath(type[1], research_center, session)\n",
    "            if camera_path.is_dir() and signals_path.is_dir():\n",
    "                # Create the meeting path for biosignal and camera + BORIS\n",
    "                for camera in c_values:\n",
    "                    exact_camera_path = Path(camera_path).joinpath(camera)\n",
    "                    exact_signals_path = Path(signals_path).joinpath(camera)\n",
    "                    if exact_camera_path.is_dir() and exact_signals_path.is_dir():\n",
    "                        boris_path = Path(exact_camera_path).joinpath(boris_ext)\n",
    "                        if boris_path.is_dir():\n",
    "                            # Quick fix of two MAAP sessions being divided TODO: Fix this\n",
    "                            if not(research_center == 'MAAP' and ((session == 'S01' and camera == 'C05') or (session == 'S03' and camera == 'C05'))):\n",
    "                                # Find exact video name\n",
    "                                video_ext = '_video.mp4'\n",
    "                                if research_center == 'GUT':\n",
    "                                    mp4_pattern = re.compile(r'^Untitled \\d+\\.mp4$')\n",
    "                                elif research_center == 'ITU-YU':\n",
    "                                    mp4_pattern = re.compile(r'^ITU-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.mp4$')\n",
    "                                elif research_center == 'MAAP':\n",
    "                                    mp4_pattern = re.compile(r'^MAAP-C\\d{2}-S\\d{2}-\\d{8}-Camera\\.AVI$')\n",
    "                                    video_ext = '_video.AVI'\n",
    "                                for files_in_camera_dir in os.listdir(exact_camera_path):\n",
    "                                    if mp4_pattern.match(files_in_camera_dir):\n",
    "                                        video_path = os.path.join(exact_camera_path, files_in_camera_dir)\n",
    "                                        print(video_path)\n",
    "                                # TODO: TRY EXCEPT FOR not matching pattern, skip iteration\n",
    "                                filename = research_center + '_' + session + '_' + camera\n",
    "                                boris_filename = filename + 'BORIS.csv'\n",
    "                                boris_target_dir = Path(target_root_dir).joinpath(research_center, boris_filename)\n",
    "                                \n",
    "                                input_filename = filename + '_input.csv'\n",
    "                                input_target_dir = Path(target_root_dir).joinpath(research_center, input_filename)\n",
    "                                \n",
    "                                # Create combined BORIS vector\n",
    "                                #get_boris_vector(boris_path, boris_target_dir)\n",
    "                                \n",
    "                                # Create one vector of biosignals, sliced BORIS and sliced video\n",
    "                                slice_vectors(\"resources/s01c01.mp4\", exact_signals_path, input_target_dir)\n",
    "\n",
    "                                # TODO: sprawdz dlaczego wektory mają różne długości \n",
    "traverse()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\153.19.52.107\\emboa\\IO3-sessions\\NEW STRUCTURE\\Camera\\GUT\\S01\\C01\\Untitled 139.mp4\n",
      "{'last_modified_time': 'Fri Jun 18 11:15:24 2021', 'last_modified_timestamp': 1624007724, 'duration': 609, 'initial_timestamp': 1624007115}\n",
      "Video opened successfully!\n",
      "EDA:  546\n",
      "TEMP:  546\n",
      "HR:  546\n",
      "video:  546\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
