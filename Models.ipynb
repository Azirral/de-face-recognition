{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:10:05.533318Z",
     "start_time": "2024-12-03T15:10:05.504161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import compute_class_weight\n",
    "from collections import Counter"
   ],
   "id": "d9c56d637ad6750d",
   "outputs": [],
   "execution_count": 313
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the input and label files from CSVs",
   "id": "64eb4c47b082c4d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:24:10.059525Z",
     "start_time": "2024-12-03T15:24:09.932995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_sequences(x_sequences, y_sequences, model):\n",
    "    filtered_x_sequences = []\n",
    "    filtered_y_sequences = []\n",
    "    if model == 'Model I':\n",
    "        for x_seq, y_seq in zip(x_sequences, y_sequences):\n",
    "                if np.any(y_seq[:, 1:] != 0) or (np.sum(y_seq[:, 0] != 0) < 2 and np.any(y_seq[:, 0] != 0)):\n",
    "                    filtered_x_sequences.append(x_seq)\n",
    "                    filtered_y_sequences.append(y_seq)\n",
    "    else:\n",
    "        for x_seq, y_seq in zip(x_sequences, y_sequences):\n",
    "                if np.any(y_seq[:, 1:] != 0):\n",
    "                    filtered_x_sequences.append(x_seq)\n",
    "                    filtered_y_sequences.append(y_seq)\n",
    "            \n",
    "    return filtered_x_sequences,filtered_y_sequences\n",
    "    "
   ],
   "id": "c185cf12d8d2d2fc",
   "outputs": [],
   "execution_count": 339
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:24:10.670799Z",
     "start_time": "2024-12-03T15:24:10.607633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_train_test_splitted_data(label_files, input_files, global_mean, global_std, test_size=0.2, random_state=42):\n",
    "    # Initialize lists to hold all sequences\n",
    "    all_x_sequences = []\n",
    "    all_y_sequences = []\n",
    "    # Process each pair of input and label files\n",
    "    for input_file, label_file in zip(input_files, label_files):\n",
    "        # Load data\n",
    "        input_df = pd.read_csv(input_file)\n",
    "        if label_file.endswith('BORIS_method_II.csv'):\n",
    "            model = 'Model II'\n",
    "            label_df = pd.read_csv(label_file)\n",
    "            labels = label_df.values / 100\n",
    "        else:\n",
    "            model = 'Model I'\n",
    "            label_df = pd.read_csv(label_file, dtype=str, na_values=[])   \n",
    "            column_names = ['Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "\n",
    "            # Create a OneHotEncoder with predefined categories\n",
    "            encoder = OneHotEncoder(categories=[column_names], handle_unknown='ignore')\n",
    "\n",
    "            # Fit and transform the label data\n",
    "            labels = pd.DataFrame(\n",
    "                encoder.fit_transform(label_df).toarray(),\n",
    "                columns=encoder.get_feature_names_out()\n",
    "            )\n",
    "        # Prepare features and labels\n",
    "        features = (input_df.values - global_mean) / global_std\n",
    "        \n",
    "        # Ensure alignment of frames\n",
    "        if features.shape[0] != labels.shape[0]:\n",
    "            print(f\"Mismatch in frames: {input_file}, {label_file}\")\n",
    "            continue\n",
    "            \n",
    "        # Sample sequences\n",
    "        x_sequences, y_sequences = create_sequences(features, labels, SEQUENCE_LENGTH, STRIDE)\n",
    "        filtered_x_sequences, filtered_y_sequences = filter_sequences(x_sequences, y_sequences, model)\n",
    "        \n",
    "        # Append to global lists\n",
    "        if filtered_x_sequences and filtered_y_sequences:\n",
    "            all_x_sequences.append(filtered_x_sequences)\n",
    "            all_y_sequences.append(filtered_y_sequences)\n",
    "            \n",
    "    all_x_sequences = np.concatenate(all_x_sequences, axis=0)\n",
    "    all_y_sequences = np.concatenate(all_y_sequences, axis=0)\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        all_x_sequences, all_y_sequences, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Convert to TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    # Shuffle, batch, and prefetch\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ],
   "id": "ae434e5ae1f7eb17",
   "outputs": [],
   "execution_count": 340
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:18:23.012673Z",
     "start_time": "2024-12-03T14:18:22.991100Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 221,
   "source": [
    "def count_method_I(all_y_sequences, emotion_labels):\n",
    "    label_counts = Counter()\n",
    "    \n",
    "    # Loop through each y_sequence in all_y_sequences\n",
    "    for y_sequence in all_y_sequences:\n",
    "        # Loop through each label_vector (timestamp) in the sequence\n",
    "        for label_vector in y_sequence:\n",
    "            # Check if all values are zero (i.e., no emotion)\n",
    "            if np.all(label_vector == 0):\n",
    "                # Count as 'Neutral' if all values are zero\n",
    "                label_counts['Neutral'] += 1\n",
    "            else:\n",
    "                # Find the label corresponding to the max value (one-hot or normalized)\n",
    "                label_index = np.argmax(label_vector)\n",
    "                label_counts[emotion_labels[label_index]] += 1\n",
    "    \n",
    "    # Compute the total number of labels\n",
    "    total_labels = sum(label_counts.values())\n",
    "    \n",
    "    # Convert the Counter to a DataFrame\n",
    "    df = pd.DataFrame.from_dict(label_counts, orient='index', columns=['Count'])\n",
    "    \n",
    "    # Add a new column for percentage\n",
    "    df['Percentage'] = (df['Count'] / total_labels * 100).round(2).astype(str) + '%'  # Format as percentage\n",
    "    \n",
    "    # Reset the index to have labels as a column\n",
    "    df = df.reset_index().rename(columns={'index': 'Label'})\n",
    "    \n",
    "    return df"
   ],
   "id": "baa1b0a66acb77ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:03:33.271277Z",
     "start_time": "2024-12-03T15:03:33.258284Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 308,
   "source": [
    "def count_method_II(all_y_sequences):\n",
    "    \n",
    "    combined_df = pd.DataFrame(all_y_sequences)\n",
    "\n",
    "    emotion_labels = ['Happy', 'Sad', 'Disgusted', 'Surprised', 'Angry', 'Scared']\n",
    "    \n",
    "    # Calculate the number of rows where each emotion is non-zero\n",
    "    non_zero_counts = (combined_df != 0).sum()  # Counts of non-zero values per column\n",
    "    total_rows = len(combined_df)  # Total number of rows\n",
    "    print(total_rows)\n",
    "    # Calculate the \"Neutral\" count (rows where all values are zero)\n",
    "    neutral_count = (combined_df.sum(axis=1) == 0).sum()\n",
    "    \n",
    "    # Add the \"Neutral\" category to the counts\n",
    "    non_zero_counts[\"Neutral\"] = neutral_count\n",
    "    \n",
    "    result_df = pd.DataFrame(non_zero_counts.items(), columns=['Label', 'Count'])\n",
    "    # Calculate the percentage for each label\n",
    "    result_df['Percentage'] = ((result_df['Count'] / total_rows) * 100).round(2).astype(str) + '%'\n",
    "\n",
    "        # Create a mapping from numbers to emotion labels\n",
    "    label_mapping = {i: emotion_labels[i] for i in range(len(emotion_labels))}\n",
    "    \n",
    "    # Replace the numerical labels with the corresponding emotion labels\n",
    "    result_df['Label'] = result_df['Label'].replace(label_mapping)\n",
    "    \n",
    "    # Display the result\n",
    "    return(result_df)"
   ],
   "id": "9e31a2d0c255647b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:20:08.173044Z",
     "start_time": "2024-12-03T11:20:08.162912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "SEQUENCE_LENGTH = 20\n",
    "STRIDE = 10\n",
    "BATCH_SIZE = 32\n",
    "INPUT_DIM = 515  # Number of features per frame (e.g., biosignals + embeddings)\n",
    "OUTPUT_DIM = 6 "
   ],
   "id": "fd9e239e08954ed1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:12:23.961999Z",
     "start_time": "2024-12-03T15:11:46.779729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to create random sequences\n",
    "def create_sequences(features, labels, sequence_length, stride):\n",
    "    x_sequences, y_sequences = [], []\n",
    "    for i in range(0, len(features) - sequence_length + 1, stride):\n",
    "        x_sequences.append(features[i:i + sequence_length])\n",
    "        y_sequences.append(labels[i:i + sequence_length])\n",
    "    return np.array(x_sequences), np.array(y_sequences)\n",
    "\n",
    "# Initialize lists to hold all sequences\n",
    "all_x_sequences = []\n",
    "all_y_sequences = []\n",
    "all_features = []\n",
    "\n",
    "sources = [\"GUT\", \"ITU-YU\", \"MAAP\"]\n",
    "base_path = \"//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/\"\n",
    "input_files, label_files = [], []\n",
    "\n",
    "for source in sources:\n",
    "    input_files.extend(glob.glob(os.path.join(base_path, source, '*_input.csv')))\n",
    "    label_files.extend(glob.glob(os.path.join(base_path, source, '*_BORIS.csv')))\n",
    "\n",
    "input_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "i = 0\n",
    "for input_file in input_files:\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    all_features.append(input_df.values)\n",
    "\n",
    "# Concatenate all features from all files to compute global mean and std\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "\n",
    "num_columns = all_features.shape[1]\n",
    "global_mean_zero = np.zeros(num_columns)\n",
    "global_std_zero = np.zeros(num_columns)\n",
    "\n",
    "# Compute column-wise statistics ignoring zeros\n",
    "for col in range(num_columns):\n",
    "    non_zero_col = all_features[:, col][all_features[:, col] != 0]  # Filter non-zero values\n",
    "    if non_zero_col.size > 0:  # Avoid empty arrays\n",
    "        global_mean_zero[col] = np.mean(non_zero_col)\n",
    "        global_std_zero[col] = np.std(non_zero_col, ddof=1)  # Use sample std dev\n",
    "    else:\n",
    "        global_mean_zero[col] = 0  # Default if no non-zero elements\n",
    "        global_std_zero[col] = 0\n",
    "\n",
    "# Output results as ndarray\n",
    "global_mean = np.array(global_mean_zero)\n",
    "global_std = np.array(global_std_zero)\n"
   ],
   "id": "3269ede97309fd73",
   "outputs": [],
   "execution_count": 314
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:26:55.680994Z",
     "start_time": "2024-12-03T15:24:35.399374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GUT_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_input.csv'))\n",
    "ITU_YU_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_input.csv'))\n",
    "MAAP_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_input.csv'))\n",
    "\n",
    "GUT_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_BORIS_method_I.csv'))\n",
    "ITU_YU_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_BORIS_method_I.csv'))\n",
    "MAAP_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_BORIS_method_I.csv'))\n",
    "\n",
    "GUT_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_BORIS_method_II.csv'))\n",
    "ITU_YU_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_BORIS_method_II.csv'))\n",
    "MAAP_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_BORIS_method_II.csv'))\n",
    "\n",
    "GUT_train_method_I, GUT_test_method_I = get_train_test_splitted_data(GUT_path_label_method_I, GUT_path_input, global_mean, global_std, test_size=0.3)\n",
    "ITU_YU_train_method_I, ITU_YU_test_method_I = get_train_test_splitted_data(ITU_YU_path_label_method_I, ITU_YU_path_input, global_mean, global_std, test_size=0.3)\n",
    "MAAP_train_method_I, MAAP_test_method_I = get_train_test_splitted_data(MAAP_path_label_method_I, MAAP_path_input, global_mean, global_std, test_size=0.3)\n",
    "\n",
    "GUT_train_method_II, GUT_test_method_II = get_train_test_splitted_data(GUT_path_label_method_II, GUT_path_input, global_mean, global_std, test_size=0.3)\n",
    "ITU_YU_train_method_II, ITU_YU_test_method_II = get_train_test_splitted_data(ITU_YU_path_label_method_II, ITU_YU_path_input, global_mean, global_std, test_size=0.3)\n",
    "MAAP_train_method_II, MAAP_test_method_II = get_train_test_splitted_data(MAAP_path_label_method_II, MAAP_path_input, global_mean, global_std, test_size=0.3)\n",
    "\n",
    "dataset_method_I = GUT_train_method_I.concatenate(ITU_YU_train_method_I).concatenate(MAAP_train_method_I)\n",
    "dataset_method_II = GUT_train_method_II.concatenate(ITU_YU_train_method_II).concatenate(MAAP_train_method_II)"
   ],
   "id": "42105060863388e",
   "outputs": [],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T13:31:11.404634Z",
     "start_time": "2024-11-27T13:30:21.482241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for input_file in input_files:\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Check if the DataFrame contains any NaN\n",
    "    if input_df.isnull().values.any():\n",
    "        print(f\"NaN found in file: {input_file}\")\n",
    "    \n",
    "    all_features.append(input_df.values)"
   ],
   "id": "e5a0b0d60d0c3b67",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:40:04.529479Z",
     "start_time": "2024-11-28T16:26:19.796129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Zakomentowane bo się cykam\n",
    "# path = r'S:\\IO3-sessions\\NEW STRUCTURE\\de-earlyfusionthesis\\Datasets'\n",
    "# \n",
    "# tf.data.Dataset.save(dataset_method_I ,os.path.join(path, 'train_dataset_method_I'))\n",
    "# tf.data.Dataset.save(GUT_train_method_I, os.path.join(path, 'GUT_train_method_I'))\n",
    "# tf.data.Dataset.save(GUT_test_method_I, os.path.join(path, 'GUT_test_method_I'))\n",
    "# tf.data.Dataset.save(ITU_YU_train_method_I, os.path.join(path, 'ITU_YU_train_method_I'))\n",
    "# tf.data.Dataset.save(ITU_YU_test_method_I, os.path.join(path, 'ITU_YU_test_method_I'))\n",
    "# tf.data.Dataset.save(MAAP_train_method_I, os.path.join(path, 'MAAP_train_method_I'))\n",
    "# tf.data.Dataset.save(MAAP_test_method_I, os.path.join(path, 'MAAP_test_method_I'))\n",
    "# \n",
    "# tf.data.Dataset.save(dataset_method_II ,os.path.join(path, 'train_dataset_method_II'))\n",
    "# tf.data.Dataset.save(GUT_train_method_II, os.path.join(path, 'GUT_train_method_II'))\n",
    "# tf.data.Dataset.save(GUT_test_method_II, os.path.join(path, 'GUT_test_method_II'))\n",
    "# tf.data.Dataset.save(ITU_YU_train_method_II, os.path.join(path, 'ITU_YU_train_method_II'))\n",
    "# tf.data.Dataset.save(ITU_YU_test_method_II, os.path.join(path, 'ITU_YU_test_method_II'))\n",
    "# tf.data.Dataset.save(MAAP_train_method_II, os.path.join(path, 'MAAP_train_method_II'))\n",
    "# tf.data.Dataset.save(MAAP_test_method_II, os.path.join(path, 'MAAP_test_method_II'))"
   ],
   "id": "aa09b06f19e78fe6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:27:55.101416Z",
     "start_time": "2024-12-03T15:27:04.040073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = r'S:\\IO3-sessions\\NEW STRUCTURE\\de-earlyfusionthesis\\Datasets'\n",
    "\n",
    "tf.data.Dataset.save(dataset_method_I ,os.path.join(path, 'train_dataset_method_I_balanced'))\n",
    "tf.data.Dataset.save(GUT_train_method_I, os.path.join(path, 'GUT_train_method_I_balanced'))\n",
    "tf.data.Dataset.save(GUT_test_method_I, os.path.join(path, 'GUT_test_method_I_balanced'))\n",
    "tf.data.Dataset.save(ITU_YU_train_method_I, os.path.join(path, 'ITU_YU_train_method_I_balanced'))\n",
    "tf.data.Dataset.save(ITU_YU_test_method_I, os.path.join(path, 'ITU_YU_test_method_I_balanced'))\n",
    "tf.data.Dataset.save(MAAP_train_method_I, os.path.join(path, 'MAAP_train_method_I_balanced'))\n",
    "tf.data.Dataset.save(MAAP_test_method_I, os.path.join(path, 'MAAP_test_method_I_balanced'))\n",
    "\n",
    "tf.data.Dataset.save(dataset_method_II ,os.path.join(path, 'train_dataset_method_II_balanced'))\n",
    "tf.data.Dataset.save(GUT_train_method_II, os.path.join(path, 'GUT_train_method_II_balanced'))\n",
    "tf.data.Dataset.save(GUT_test_method_II, os.path.join(path, 'GUT_test_method_II_balanced'))\n",
    "tf.data.Dataset.save(ITU_YU_train_method_II, os.path.join(path, 'ITU_YU_train_method_II_balanced'))\n",
    "tf.data.Dataset.save(ITU_YU_test_method_II, os.path.join(path, 'ITU_YU_test_method_II_balanced'))\n",
    "tf.data.Dataset.save(MAAP_train_method_II, os.path.join(path, 'MAAP_train_method_II_balanced'))\n",
    "tf.data.Dataset.save(MAAP_test_method_II, os.path.join(path, 'MAAP_test_method_II_balanced'))"
   ],
   "id": "819133b94da11c45",
   "outputs": [],
   "execution_count": 342
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:27:55.122996Z",
     "start_time": "2024-12-03T15:27:55.111953Z"
    }
   },
   "cell_type": "code",
   "source": "path = r'S:\\IO3-sessions\\NEW STRUCTURE\\de-earlyfusionthesis\\Models'",
   "id": "f5858e51c3ae1e4",
   "outputs": [],
   "execution_count": 343
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MODEL I",
   "id": "dd354b421e7b7df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:27:55.527625Z",
     "start_time": "2024-12-03T15:27:55.176882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_I = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),    # Input shape: (sequence_length, features)\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),  # LSTM layer to capture temporal patterns\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                 # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='softmax')       # Output layer with sigmoid for continuous values between 0 and 1\n",
    "])"
   ],
   "id": "e2ad7b207850414f",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T16:40:05.389407Z",
     "start_time": "2024-11-28T16:40:04.844666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_masking(inputs):\n",
    "    # Create a mask where any feature being 0 masks the entire time step\n",
    "    mask = tf.reduce_all(tf.not_equal(inputs, 0.0), axis=-1)  # True if no feature is 0\n",
    "    return tf.where(mask[:, :, tf.newaxis], inputs, tf.zeros_like(inputs))\n",
    "\n",
    "# Model with custom masking\n",
    "model_I = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),   # Input shape\n",
    "    tf.keras.layers.Lambda(custom_masking),                      # Custom masking layer\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),  # Bidirectional LSTM\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='softmax')      # Output layer with softmax for class probabilities\n",
    "])"
   ],
   "id": "f3e058ede3e15f98",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:27:55.629071Z",
     "start_time": "2024-12-03T15:27:55.603557Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "id": "173e19cf70c8f6c7",
   "outputs": [],
   "execution_count": 345
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T13:14:53.788238Z",
     "start_time": "2024-11-28T13:14:49.080176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through the dataset to extract labels\n",
    "labels = []\n",
    "\n",
    "for inputs, label in dataset_method_I:\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert to a tensor or numpy array\n",
    "y_train = np.concatenate(labels, axis=0)  # Stack labels into a single array\n",
    "y_train_flat = y_train.reshape(-1, 6)  # Flattening the labels: (num_samples * 10, 6)\n",
    "y_train_classes = np.argmax(y_train_flat, axis=-1)  # Get the class labels for each timestep (0 to 5)\n",
    "\n",
    "# Calculate class weights based on the frequency of each class\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_classes), y=y_train_classes)\n",
    "\n",
    "# Convert class_weights into a dictionary format for fit() function\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ],
   "id": "f84b4dd1b5357177",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T13:14:54.795169Z",
     "start_time": "2024-11-28T13:14:54.779014Z"
    }
   },
   "cell_type": "code",
   "source": "print(class_weights)",
   "id": "d45925f5ce6896ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69060938e-01 2.54473304e+01 2.90288066e+01 5.34393939e+02\n",
      " 2.02701149e+02 2.26089744e+02]\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T13:14:56.831609Z",
     "start_time": "2024-11-28T13:14:56.824427Z"
    }
   },
   "cell_type": "code",
   "source": "print(class_weight_dict)",
   "id": "1123818c70420704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.1690609376722605, 1: 25.447330447330447, 2: 29.02880658436214, 3: 534.3939393939394, 4: 202.70114942528735, 5: 226.0897435897436}\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:12.201670Z",
     "start_time": "2024-12-03T15:27:55.894579Z"
    }
   },
   "cell_type": "code",
   "source": "history = model_I.fit(dataset_method_I, epochs=50, batch_size=BATCH_SIZE)",
   "id": "19ccb585dcf4bcaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 19ms/step - accuracy: 0.5008 - loss: 0.3837\n",
      "Epoch 2/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.1967 - loss: 0.3447\n",
      "Epoch 3/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.1297 - loss: 0.3384\n",
      "Epoch 4/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.1577 - loss: 0.3030\n",
      "Epoch 5/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.1169 - loss: 0.3111\n",
      "Epoch 6/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - accuracy: 0.1272 - loss: 0.3336\n",
      "Epoch 7/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.0789 - loss: 0.3335\n",
      "Epoch 8/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.0410 - loss: 0.3431\n",
      "Epoch 9/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.0463 - loss: 0.3532\n",
      "Epoch 10/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0467 - loss: 0.3474\n",
      "Epoch 11/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0369 - loss: 0.3504\n",
      "Epoch 12/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0414 - loss: 0.3671\n",
      "Epoch 13/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0344 - loss: 0.3705\n",
      "Epoch 14/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0402 - loss: 0.3575\n",
      "Epoch 15/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0402 - loss: 0.3546\n",
      "Epoch 16/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0399 - loss: 0.3616\n",
      "Epoch 17/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0442 - loss: 0.3445\n",
      "Epoch 18/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0400 - loss: 0.3402\n",
      "Epoch 19/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0344 - loss: 0.3459\n",
      "Epoch 20/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0411 - loss: 0.3565\n",
      "Epoch 21/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.0404 - loss: 0.3541\n",
      "Epoch 22/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0325 - loss: 0.3502\n",
      "Epoch 23/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0490 - loss: 0.3617\n",
      "Epoch 24/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0353 - loss: 0.3578\n",
      "Epoch 25/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0281 - loss: 0.3565\n",
      "Epoch 26/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0324 - loss: 0.3543\n",
      "Epoch 27/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - accuracy: 0.0253 - loss: 0.3610\n",
      "Epoch 28/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.0358 - loss: 0.3581\n",
      "Epoch 29/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0273 - loss: 0.3540\n",
      "Epoch 30/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0336 - loss: 0.3679\n",
      "Epoch 31/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0353 - loss: 0.3502\n",
      "Epoch 32/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0337 - loss: 0.3555\n",
      "Epoch 33/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.0409 - loss: 0.3787\n",
      "Epoch 34/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.0253 - loss: 0.3521\n",
      "Epoch 35/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.0287 - loss: 0.3705\n",
      "Epoch 36/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.0446 - loss: 0.3661\n",
      "Epoch 37/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.0358 - loss: 0.3717\n",
      "Epoch 38/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.0381 - loss: 0.3563\n",
      "Epoch 39/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0347 - loss: 0.3713\n",
      "Epoch 40/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0361 - loss: 0.3554\n",
      "Epoch 41/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - accuracy: 0.0363 - loss: 0.3626\n",
      "Epoch 42/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.1336 - loss: 0.3543\n",
      "Epoch 43/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.0383 - loss: 0.3650\n",
      "Epoch 44/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2059 - loss: 0.3831\n",
      "Epoch 45/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.0547 - loss: 0.3932\n",
      "Epoch 46/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.2140 - loss: 0.3589\n",
      "Epoch 47/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - accuracy: 0.1402 - loss: 0.3961\n",
      "Epoch 48/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.1465 - loss: 0.3630\n",
      "Epoch 49/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.2219 - loss: 0.3490\n",
      "Epoch 50/50\n",
      "\u001B[1m10/10\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.2202 - loss: 0.3785\n"
     ]
    }
   ],
   "execution_count": 346
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:12.502477Z",
     "start_time": "2024-12-03T15:28:12.401935Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.summary()",
   "id": "6235f654319c897",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (\u001B[38;5;33mBidirectional\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │       \u001B[38;5;34m296,960\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │         \u001B[38;5;34m4,128\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m6\u001B[0m)          │           \u001B[38;5;34m198\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">296,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m903,860\u001B[0m (3.45 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">903,860</span> (3.45 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m301,286\u001B[0m (1.15 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,286</span> (1.15 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m602,574\u001B[0m (2.30 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">602,574</span> (2.30 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 347
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:15.080758Z",
     "start_time": "2024-12-03T15:28:13.651037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, acc = model_I.evaluate(MAAP_test_method_I, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(acc))"
   ],
   "id": "8b4a500ad36da8b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 1s - 468ms/step - accuracy: 0.0736 - loss: 0.4225\n",
      "Untrained model, accuracy:  0.07%\n"
     ]
    }
   ],
   "execution_count": 348
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:28:16.460686Z",
     "start_time": "2024-12-03T15:28:15.274540Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.save(os.path.join(path, 'model_method_I/model.keras'))",
   "id": "914d4b9b7968270e",
   "outputs": [],
   "execution_count": 349
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-28T13:13:29.831093Z",
     "start_time": "2024-11-28T13:13:24.393580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for inputs, labels in dataset_method_I.take(1):  # Take a small batch\n",
    "    preds = model_I.predict(inputs)\n",
    "    print(\"Predictions:\", preds)\n",
    "    print(\"Ground Truth:\", labels)"
   ],
   "id": "c20461eeef6e3db7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2s/step\n",
      "Predictions: [[[0.18423472 0.18805367 0.15358369 0.15975992 0.14348555 0.17088243]\n",
      "  [0.18988968 0.13390423 0.15667434 0.17703208 0.17288329 0.16961627]\n",
      "  [0.15876924 0.12157965 0.1510373  0.21069701 0.19562545 0.16229136]\n",
      "  ...\n",
      "  [0.2360522  0.11189648 0.14936432 0.21476454 0.17604093 0.11188145]\n",
      "  [0.19055042 0.13608056 0.1481003  0.2175018  0.17827131 0.1294956 ]\n",
      "  [0.1851553  0.13742118 0.17442626 0.21284981 0.16557454 0.1245729 ]]\n",
      "\n",
      " [[0.12943289 0.15690541 0.24211912 0.20530048 0.16510516 0.10113697]\n",
      "  [0.1359072  0.12828828 0.29404885 0.22961743 0.13318458 0.07895364]\n",
      "  [0.15133195 0.1261013  0.30664647 0.21946089 0.11806839 0.07839099]\n",
      "  ...\n",
      "  [0.16341293 0.13049836 0.26789552 0.14440988 0.19457927 0.099204  ]\n",
      "  [0.16080208 0.12511742 0.27074748 0.20283565 0.16643985 0.07405749]\n",
      "  [0.2062359  0.11890065 0.2678376  0.18631993 0.14456865 0.07613719]]\n",
      "\n",
      " [[0.16589867 0.12919189 0.14554487 0.19906464 0.21806522 0.14223465]\n",
      "  [0.19285446 0.07644825 0.18688047 0.21479225 0.22435686 0.10466769]\n",
      "  [0.17987897 0.08268321 0.19224143 0.17265688 0.24327035 0.12926918]\n",
      "  ...\n",
      "  [0.1384069  0.10035643 0.24325503 0.2040781  0.21910186 0.09480166]\n",
      "  [0.12846313 0.08286978 0.23986064 0.23609433 0.22056016 0.09215194]\n",
      "  [0.12654956 0.09378416 0.1984661  0.22944023 0.24536413 0.10639582]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.13620341 0.26329744 0.1821408  0.11290701 0.20839255 0.09705881]\n",
      "  [0.1312493  0.29051304 0.179277   0.10206093 0.20020062 0.09669916]\n",
      "  [0.1310075  0.2864934  0.17975336 0.09956019 0.20568615 0.09749944]\n",
      "  ...\n",
      "  [0.1204858  0.2802237  0.1238431  0.07756142 0.28242448 0.11546145]\n",
      "  [0.12106413 0.26352748 0.17094952 0.09269293 0.24429263 0.10747328]\n",
      "  [0.12665696 0.19985682 0.16729034 0.10154961 0.2980807  0.1065655 ]]\n",
      "\n",
      " [[0.23578766 0.12978928 0.08011912 0.18134964 0.19931325 0.17364116]\n",
      "  [0.22687224 0.14921552 0.09825789 0.15810843 0.19839203 0.16915396]\n",
      "  [0.20195794 0.12278546 0.09480078 0.18927376 0.22815664 0.16302542]\n",
      "  ...\n",
      "  [0.18014841 0.16386239 0.17325644 0.15342626 0.16739793 0.16190848]\n",
      "  [0.20668776 0.17408206 0.15486336 0.11031816 0.15282582 0.20122285]\n",
      "  [0.20561142 0.15072544 0.15330224 0.16597757 0.18033406 0.14404926]]\n",
      "\n",
      " [[0.16859928 0.08932362 0.21051314 0.18927334 0.21965386 0.12263676]\n",
      "  [0.16733907 0.0825196  0.2081283  0.18238266 0.21193238 0.14769803]\n",
      "  [0.1330055  0.11631298 0.17815211 0.17701364 0.20082511 0.19469067]\n",
      "  ...\n",
      "  [0.13386056 0.14184833 0.23690912 0.1924252  0.17876384 0.11619292]\n",
      "  [0.12294044 0.14457792 0.21988659 0.22156121 0.16606194 0.1249719 ]\n",
      "  [0.12672731 0.15642405 0.20381057 0.22357817 0.149866   0.13959393]]]\n",
      "Ground Truth: tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]], shape=(32, 20, 6), dtype=float64)\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MODEL II",
   "id": "b53443af5c334d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:21:49.472518Z",
     "start_time": "2024-12-03T15:21:48.701818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_II = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),    # Input shape: (sequence_length, features)\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),              # LSTM layer to capture temporal patterns\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                 # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='sigmoid')       # Output layer with sigmoid for continuous values between 0 and 1\n",
    "])"
   ],
   "id": "8ae51ea52a2bf3b6",
   "outputs": [],
   "execution_count": 333
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def mask_timestep(inputs):\n",
    "    # Mask timesteps where any feature is 0\n",
    "    # tf.reduce_any checks if any feature in the timestep is 0\n",
    "    mask = tf.reduce_any(tf.equal(inputs, 0.0), axis=-1)  # Create mask for timesteps with any 0\n",
    "    return mask\n",
    "\n",
    "# Input Layer\n",
    "inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM))\n",
    "\n",
    "# Apply the custom masking logic\n",
    "mask = tf.keras.layers.Lambda(mask_timestep)(inputs)\n",
    "\n",
    "# Apply the mask to the input sequence (this will zero out timesteps that have missing values)\n",
    "masked_inputs = tf.keras.layers.Masking(mask_value=0.0)(inputs)\n",
    "\n",
    "# LSTM layers to process the masked inputs\n",
    "lstm_output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(masked_inputs)\n",
    "\n",
    "# Dense layers\n",
    "dense_output = tf.keras.layers.Dense(32, activation='relu')(lstm_output)\n",
    "output = tf.keras.layers.Dense(OUTPUT_DIM, activation='sigmoid')(dense_output)\n",
    "\n",
    "# Build and compile the model\n",
    "model_I = tf.keras.Model(inputs=inputs, outputs=output)"
   ],
   "id": "5be0ce81f4096c19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:21:54.622547Z",
     "start_time": "2024-12-03T15:21:54.583125Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])",
   "id": "372ce70cf7533e58",
   "outputs": [],
   "execution_count": 334
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:22:36.542290Z",
     "start_time": "2024-12-03T15:21:55.500820Z"
    }
   },
   "cell_type": "code",
   "source": "history = model_II.fit(dataset_method_II, epochs=50)",
   "id": "90c6f6be681e7739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 40ms/step - loss: 0.1417 - mae: 0.3394\n",
      "Epoch 2/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0313 - mae: 0.1330\n",
      "Epoch 3/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0199 - mae: 0.0854\n",
      "Epoch 4/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 0.0186 - mae: 0.0752\n",
      "Epoch 5/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 0.0172 - mae: 0.0691\n",
      "Epoch 6/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 0.0170 - mae: 0.0683\n",
      "Epoch 7/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 0.0160 - mae: 0.0657\n",
      "Epoch 8/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 0.0162 - mae: 0.0648\n",
      "Epoch 9/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0159 - mae: 0.0627\n",
      "Epoch 10/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0153 - mae: 0.0622\n",
      "Epoch 11/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0153 - mae: 0.0617\n",
      "Epoch 12/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 0.0147 - mae: 0.0610\n",
      "Epoch 13/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0143 - mae: 0.0601\n",
      "Epoch 14/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0134 - mae: 0.0569\n",
      "Epoch 15/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0130 - mae: 0.0555\n",
      "Epoch 16/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0135 - mae: 0.0568\n",
      "Epoch 17/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.0130 - mae: 0.0558\n",
      "Epoch 18/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0126 - mae: 0.0530\n",
      "Epoch 19/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 0.0119 - mae: 0.0535\n",
      "Epoch 20/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0121 - mae: 0.0523\n",
      "Epoch 21/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 0.0119 - mae: 0.0526\n",
      "Epoch 22/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0121 - mae: 0.0513\n",
      "Epoch 23/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 0.0114 - mae: 0.0509\n",
      "Epoch 24/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0119 - mae: 0.0522\n",
      "Epoch 25/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0111 - mae: 0.0509\n",
      "Epoch 26/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0108 - mae: 0.0504\n",
      "Epoch 27/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0108 - mae: 0.0506\n",
      "Epoch 28/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0102 - mae: 0.0484\n",
      "Epoch 29/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 0.0107 - mae: 0.0468\n",
      "Epoch 30/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0104 - mae: 0.0496\n",
      "Epoch 31/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 0.0105 - mae: 0.0478\n",
      "Epoch 32/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 0.0105 - mae: 0.0492\n",
      "Epoch 33/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0105 - mae: 0.0477\n",
      "Epoch 34/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0102 - mae: 0.0459\n",
      "Epoch 35/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0096 - mae: 0.0481\n",
      "Epoch 36/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0101 - mae: 0.0475\n",
      "Epoch 37/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0108 - mae: 0.0479\n",
      "Epoch 38/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0105 - mae: 0.0471\n",
      "Epoch 39/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0105 - mae: 0.0481\n",
      "Epoch 40/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step - loss: 0.0099 - mae: 0.0453\n",
      "Epoch 41/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 18ms/step - loss: 0.0095 - mae: 0.0451\n",
      "Epoch 42/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0091 - mae: 0.0449\n",
      "Epoch 43/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 0.0090 - mae: 0.0443\n",
      "Epoch 44/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0090 - mae: 0.0461\n",
      "Epoch 45/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 20ms/step - loss: 0.0091 - mae: 0.0436\n",
      "Epoch 46/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 0.0092 - mae: 0.0452\n",
      "Epoch 47/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0091 - mae: 0.0425\n",
      "Epoch 48/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0089 - mae: 0.0444\n",
      "Epoch 49/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 0.0094 - mae: 0.0446\n",
      "Epoch 50/50\n",
      "\u001B[1m27/27\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 0.0084 - mae: 0.0429\n"
     ]
    }
   ],
   "execution_count": 335
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:22:36.726308Z",
     "start_time": "2024-12-03T15:22:36.630379Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.summary()",
   "id": "a934e87493baa466",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │       \u001B[38;5;34m148,480\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m6\u001B[0m)          │           \u001B[38;5;34m198\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m452,276\u001B[0m (1.73 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452,276</span> (1.73 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m150,758\u001B[0m (588.90 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,758</span> (588.90 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m301,518\u001B[0m (1.15 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,518</span> (1.15 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 336
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:22:37.987577Z",
     "start_time": "2024-12-03T15:22:36.950975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, acc = model_II.evaluate(MAAP_test_method_II, verbose=2)\n",
    "print(\"Untrained model, coherence: {:5.2f}%\".format(100 * (1-acc)))"
   ],
   "id": "5d5d5465ef467740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 1s - 103ms/step - loss: 0.0179 - mae: 0.0647\n",
      "Untrained model, coherence: 93.53%\n"
     ]
    }
   ],
   "execution_count": 337
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T15:22:38.514072Z",
     "start_time": "2024-12-03T15:22:38.145809Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.save(os.path.join(path, 'model_method_II/model.keras'))",
   "id": "4f814446e3673c61",
   "outputs": [],
   "execution_count": 338
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "ef738c8d809ab7ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:51:43.871518Z",
     "start_time": "2024-11-27T00:51:43.854370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout"
   ],
   "id": "4aee6213cfffbc5",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.218835Z",
     "start_time": "2024-11-27T01:00:10.208197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_positional_encoding(sequence_length, input_dim):\n",
    "    \"\"\"\n",
    "    Generate a positional encoding matrix for the transformer model.\n",
    "    This encoding is added to the input data to give the model an understanding of the order of the sequence.\n",
    "    \"\"\"\n",
    "    position = np.arange(sequence_length)[:, np.newaxis]  # Shape: (sequence_length, 1)\n",
    "    div_term = np.exp(np.arange(0, input_dim, 2) * -(np.log(10000.0) / input_dim))  # Shape: (input_dim // 2,)\n",
    "    \n",
    "    pos_enc = np.zeros((sequence_length, input_dim))  # Shape: (sequence_length, input_dim)\n",
    "    \n",
    "    # Apply sine to even indices (0, 2, 4, ...)\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)  # Apply sine to even indices (0, 2, 4, ...)\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term)\n",
    "    # Apply cosine to odd indices (1, 3, 5, ...)\n",
    "    if input_dim % 2 != 0:  # Even input_dim\n",
    "        pos_enc[:, -1] = np.sin(position * div_term[-1])  # If odd, handle the last dimension separately\n",
    "\n",
    "    return tf.constant(pos_enc, dtype=tf.float32)\n",
    "\n"
   ],
   "id": "5d0c84a9b72f3415",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.829573Z",
     "start_time": "2024-11-27T01:00:10.813862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate):\n",
    "    # Multi-Head Self Attention Layer\n",
    "    attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout_rate)(inputs, inputs)\n",
    "    \n",
    "    # Skip connection and normalization\n",
    "    x = tf.keras.layers.Add()([inputs, attention_output])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    # Feed-forward network\n",
    "    ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ffn_output = tf.keras.layers.Dense(inputs.shape[-1])(ffn_output)\n",
    "    \n",
    "    # Skip connection and normalization\n",
    "    x = tf.keras.layers.Add()([x, ffn_output])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    return x"
   ],
   "id": "78127408d3a5f6b4",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.880936Z",
     "start_time": "2024-11-27T01:00:10.869590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_transformer_model(sequence_length, input_dim, output_dim, num_heads=8, ff_dim=128, num_layers=4, dropout_rate=0.1):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, input_dim))  # Input shape\n",
    "    \n",
    "    # Add positional encoding to inputs\n",
    "    pos_encoding = get_positional_encoding(sequence_length, input_dim)\n",
    "    x = tf.keras.layers.Add()([inputs, pos_encoding])  # Adding positional encoding to input\n",
    "    \n",
    "    # Pass through multiple Transformer encoder blocks\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_encoder(x, head_size=input_dim, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(output_dim, activation='sigmoid')(x)  # Output layer with 6 emotions\n",
    "    \n",
    "    # Build the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ],
   "id": "2acefd7865f5d0ae",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:11.690059Z",
     "start_time": "2024-11-27T01:00:11.609319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset dimensions (example values)\n",
    "sequence_length = 10  # Length of each sequence (e.g., 10 frames per video)\n",
    "input_dim = 515  # Number of features per timestep (e.g., face embeddings with 515 features)\n",
    "output_dim = 6  # Number of classes (emotions)\n",
    "\n",
    "# Build the model\n",
    "model = build_transformer_model(sequence_length, input_dim, output_dim)"
   ],
   "id": "2ee64a4daf5a35b8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,258) into shape (10,257)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[105], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m output_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m6\u001B[39m  \u001B[38;5;66;03m# Number of classes (emotions)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Build the model\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_transformer_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[104], line 5\u001B[0m, in \u001B[0;36mbuild_transformer_model\u001B[1;34m(sequence_length, input_dim, output_dim, num_heads, ff_dim, num_layers, dropout_rate)\u001B[0m\n\u001B[0;32m      2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(sequence_length, input_dim))  \u001B[38;5;66;03m# Input shape\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Add positional encoding to inputs\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m pos_encoding \u001B[38;5;241m=\u001B[39m \u001B[43mget_positional_encoding\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mAdd()([inputs, pos_encoding])  \u001B[38;5;66;03m# Adding positional encoding to input\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Pass through multiple Transformer encoder blocks\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[102], line 13\u001B[0m, in \u001B[0;36mget_positional_encoding\u001B[1;34m(sequence_length, input_dim)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Apply sine to even indices (0, 2, 4, ...)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m pos_enc[:, \u001B[38;5;241m0\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msin(position \u001B[38;5;241m*\u001B[39m div_term)  \u001B[38;5;66;03m# Apply sine to even indices (0, 2, 4, ...)\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[43mpos_enc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcos(position \u001B[38;5;241m*\u001B[39m div_term)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Apply cosine to odd indices (1, 3, 5, ...)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m# Even input_dim\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: could not broadcast input array from shape (10,258) into shape (10,257)"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Assuming you have `X_train` and `y_train` loaded from your dataset\n",
    "# Model training\n",
    "history = model.fit(dataset_method_I,epochs=50, batch_size=32)"
   ],
   "id": "53f62401fe8c9038"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5d887569df7289f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
