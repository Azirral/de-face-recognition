{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:58:35.687682Z",
     "start_time": "2024-11-27T16:58:35.665675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import compute_class_weight"
   ],
   "id": "d9c56d637ad6750d",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get the input and label files from CSVs",
   "id": "64eb4c47b082c4d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T13:26:59.938701Z",
     "start_time": "2024-11-27T13:26:59.924135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_train_test_splitted_data(label_files, input_files, global_mean, global_std, test_size=0.2, random_state=42):\n",
    "    # Initialize lists to hold all sequences\n",
    "    all_x_sequences = []\n",
    "    all_y_sequences = []\n",
    "\n",
    "    # Process each pair of input and label files\n",
    "    for input_file, label_file in zip(input_files, label_files):\n",
    "        # Load data\n",
    "        input_df = pd.read_csv(input_file)\n",
    "        if label_file.endswith('BORIS_method_II.csv'):\n",
    "            label_df = pd.read_csv(label_file)\n",
    "        else:\n",
    "            label_df = pd.read_csv(label_file, dtype=str, na_values=[])    \n",
    "        # Prepare features and labels\n",
    "        features = (input_df.values - global_mean) / global_std\n",
    "        \n",
    "        if label_file.endswith('BORIS_method_II.csv'):\n",
    "            labels = label_df.values / 100\n",
    "        else:\n",
    "            # Define the possible categories explicitly\n",
    "            column_names = ['Happy', 'Sad', 'Scared', 'Disgusted', 'Surprised', 'Angry']\n",
    "\n",
    "            # Create a OneHotEncoder with predefined categories\n",
    "            encoder = OneHotEncoder(categories=[column_names], handle_unknown='ignore')\n",
    "\n",
    "            # Fit and transform the label data\n",
    "            labels = pd.DataFrame(\n",
    "                encoder.fit_transform(label_df).toarray(),\n",
    "                columns=encoder.get_feature_names_out()\n",
    "            )\n",
    "\n",
    "        # Ensure alignment of frames\n",
    "        if features.shape[0] != labels.shape[0]:\n",
    "            print(f\"Mismatch in frames: {input_file}, {label_file}\")\n",
    "            continue\n",
    "            \n",
    "        # Sample sequences\n",
    "        x_sequences, y_sequences = create_sequences(features, labels, SEQUENCE_LENGTH, STRIDE)\n",
    "\n",
    "        # Append to global lists\n",
    "        all_x_sequences.append(x_sequences)\n",
    "        all_y_sequences.append(y_sequences)\n",
    "        \n",
    "    # Concatenate all sequences from all files\n",
    "    all_x_sequences = np.concatenate(all_x_sequences, axis=0)\n",
    "    all_y_sequences = np.concatenate(all_y_sequences, axis=0)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        all_x_sequences, all_y_sequences, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Convert to TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "    # Shuffle, batch, and prefetch\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ],
   "id": "ae434e5ae1f7eb17",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T13:27:00.529011Z",
     "start_time": "2024-11-27T13:27:00.523467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Constants\n",
    "SEQUENCE_LENGTH = 20\n",
    "STRIDE = 10\n",
    "BATCH_SIZE = 32\n",
    "INPUT_DIM = 515  # Number of features per frame (e.g., biosignals + embeddings)\n",
    "OUTPUT_DIM = 6 "
   ],
   "id": "fd9e239e08954ed1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:15:31.305685Z",
     "start_time": "2024-11-27T16:14:38.672977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to create random sequences\n",
    "def create_sequences(features, labels, sequence_length, stride):\n",
    "    x_sequences, y_sequences = [], []\n",
    "    for i in range(0, len(features) - sequence_length + 1, stride):\n",
    "        x_sequences.append(features[i:i + sequence_length])\n",
    "        y_sequences.append(labels[i:i + sequence_length])\n",
    "    return np.array(x_sequences), np.array(y_sequences)\n",
    "\n",
    "# Initialize lists to hold all sequences\n",
    "all_x_sequences = []\n",
    "all_y_sequences = []\n",
    "all_features = []\n",
    "\n",
    "sources = [\"GUT\", \"ITU-YU\", \"MAAP\"]\n",
    "base_path = \"//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/\"\n",
    "input_files, label_files = [], []\n",
    "\n",
    "for source in sources:\n",
    "    input_files.extend(glob.glob(os.path.join(base_path, source, '*_input.csv')))\n",
    "    label_files.extend(glob.glob(os.path.join(base_path, source, '*_BORIS.csv')))\n",
    "\n",
    "input_files.sort()\n",
    "label_files.sort()\n",
    "\n",
    "i = 0\n",
    "for input_file in input_files:\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    all_features.append(input_df.values)\n",
    "\n",
    "# Concatenate all features from all files to compute global mean and std\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "\n",
    "num_columns = all_features.shape[1]\n",
    "global_mean_zero = np.zeros(num_columns)\n",
    "global_std_zero = np.zeros(num_columns)\n",
    "\n",
    "# Compute column-wise statistics ignoring zeros\n",
    "for col in range(num_columns):\n",
    "    non_zero_col = all_features[:, col][all_features[:, col] != 0]  # Filter non-zero values\n",
    "    if non_zero_col.size > 0:  # Avoid empty arrays\n",
    "        global_mean_zero[col] = np.mean(non_zero_col)\n",
    "        global_std_zero[col] = np.std(non_zero_col, ddof=1)  # Use sample std dev\n",
    "    else:\n",
    "        global_mean_zero[col] = 0  # Default if no non-zero elements\n",
    "        global_std_zero[col] = 0\n",
    "\n",
    "# Output results as ndarray\n",
    "global_mean = np.array(global_mean_zero)\n",
    "global_std = np.array(global_std_zero)\n"
   ],
   "id": "3269ede97309fd73",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:17:51.932112Z",
     "start_time": "2024-11-27T16:15:57.762585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "GUT_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_input.csv'))\n",
    "ITU_YU_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_input.csv'))\n",
    "MAAP_path_input = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_input.csv'))\n",
    "\n",
    "GUT_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_BORIS_method_I.csv'))\n",
    "ITU_YU_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_BORIS_method_I.csv'))\n",
    "MAAP_path_label_method_I = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_BORIS_method_I.csv'))\n",
    "\n",
    "GUT_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/GUT/*_BORIS_method_II.csv'))\n",
    "ITU_YU_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/ITU-YU/*_BORIS_method_II.csv'))\n",
    "MAAP_path_label_method_II = sorted(glob.glob('//153.19.52.107/emboa/IO3-sessions/NEW STRUCTURE/de-earlyfusionthesis/MAAP/*_BORIS_method_II.csv'))\n",
    "\n",
    "GUT_train_method_I, GUT_test_method_I = get_train_test_splitted_data(GUT_path_label_method_I, GUT_path_input, global_mean, global_std, test_size=0.3)\n",
    "ITU_YU_train_method_I, ITU_YU_test_method_I = get_train_test_splitted_data(ITU_YU_path_label_method_I, ITU_YU_path_input, global_mean, global_std, test_size=0.3)\n",
    "MAAP_train_method_I, MAAP_test_method_I = get_train_test_splitted_data(MAAP_path_label_method_I, MAAP_path_input, global_mean, global_std, test_size=0.3)\n",
    "\n",
    "GUT_train_method_II, GUT_test_method_II = get_train_test_splitted_data(GUT_path_label_method_II, GUT_path_input, global_mean, global_std, test_size=0.3)\n",
    "ITU_YU_train_method_II, ITU_YU_test_method_II = get_train_test_splitted_data(ITU_YU_path_label_method_II, ITU_YU_path_input, global_mean, global_std, test_size=0.3)\n",
    "MAAP_train_method_II, MAAP_test_method_II = get_train_test_splitted_data(MAAP_path_label_method_II, MAAP_path_input, global_mean, global_std, test_size=0.3)\n",
    "\n",
    "dataset_method_I = GUT_train_method_I.concatenate(ITU_YU_train_method_I).concatenate(MAAP_train_method_I)\n",
    "dataset_method_II = GUT_train_method_II.concatenate(ITU_YU_train_method_II).concatenate(MAAP_train_method_II)"
   ],
   "id": "42105060863388e",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T13:31:11.404634Z",
     "start_time": "2024-11-27T13:30:21.482241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for input_file in input_files:\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Check if the DataFrame contains any NaN\n",
    "    if input_df.isnull().values.any():\n",
    "        print(f\"NaN found in file: {input_file}\")\n",
    "    \n",
    "    all_features.append(input_df.values)"
   ],
   "id": "e5a0b0d60d0c3b67",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:21:48.205501Z",
     "start_time": "2024-11-27T16:18:03.758746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = r'S:\\IO3-sessions\\NEW STRUCTURE\\de-earlyfusionthesis\\Datasets'\n",
    "\n",
    "tf.data.Dataset.save(dataset_method_I ,os.path.join(path, 'train_dataset_method_I'))\n",
    "tf.data.Dataset.save(GUT_train_method_I, os.path.join(path, 'GUT_train_method_I'))\n",
    "tf.data.Dataset.save(GUT_test_method_I, os.path.join(path, 'GUT_test_method_I'))\n",
    "tf.data.Dataset.save(ITU_YU_train_method_I, os.path.join(path, 'ITU_YU_train_method_I'))\n",
    "tf.data.Dataset.save(ITU_YU_test_method_I, os.path.join(path, 'ITU_YU_test_method_I'))\n",
    "tf.data.Dataset.save(MAAP_train_method_I, os.path.join(path, 'MAAP_train_method_I'))\n",
    "tf.data.Dataset.save(MAAP_test_method_I, os.path.join(path, 'MAAP_test_method_I'))\n",
    "\n",
    "tf.data.Dataset.save(dataset_method_II ,os.path.join(path, 'train_dataset_method_II'))\n",
    "tf.data.Dataset.save(GUT_train_method_II, os.path.join(path, 'GUT_train_method_II'))\n",
    "tf.data.Dataset.save(GUT_test_method_II, os.path.join(path, 'GUT_test_method_II'))\n",
    "tf.data.Dataset.save(ITU_YU_train_method_II, os.path.join(path, 'ITU_YU_train_method_II'))\n",
    "tf.data.Dataset.save(ITU_YU_test_method_II, os.path.join(path, 'ITU_YU_test_method_II'))\n",
    "tf.data.Dataset.save(MAAP_train_method_II, os.path.join(path, 'MAAP_train_method_II'))\n",
    "tf.data.Dataset.save(MAAP_test_method_II, os.path.join(path, 'MAAP_test_method_II'))"
   ],
   "id": "aa09b06f19e78fe6",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T16:21:56.979352Z",
     "start_time": "2024-11-27T16:21:56.967310Z"
    }
   },
   "cell_type": "code",
   "source": "path = r'S:\\IO3-sessions\\NEW STRUCTURE\\de-earlyfusionthesis\\Models'",
   "id": "f5858e51c3ae1e4",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MODEL I",
   "id": "dd354b421e7b7df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:21:55.454693Z",
     "start_time": "2024-11-26T23:21:55.394501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_I = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),    # Input shape: (sequence_length, features)\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),              # LSTM layer to capture temporal patterns\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                 # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='softmax')       # Output layer with sigmoid for continuous values between 0 and 1\n",
    "])"
   ],
   "id": "e2ad7b207850414f",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:05:22.410824Z",
     "start_time": "2024-11-27T17:05:22.319970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_masking(inputs):\n",
    "    # Create a mask where any feature being 0 masks the entire time step\n",
    "    mask = tf.reduce_all(tf.not_equal(inputs, 0.0), axis=-1)  # True if no feature is 0\n",
    "    return tf.where(mask[:, :, tf.newaxis], inputs, tf.zeros_like(inputs))\n",
    "\n",
    "# Model with custom masking\n",
    "model_I = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),   # Input shape\n",
    "    tf.keras.layers.Lambda(custom_masking),                      # Custom masking layer\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),  # Bidirectional LSTM\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='softmax')      # Output layer with softmax for class probabilities\n",
    "])"
   ],
   "id": "f3e058ede3e15f98",
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:05:23.119279Z",
     "start_time": "2024-11-27T17:05:23.099643Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
   "id": "173e19cf70c8f6c7",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:05:23.710122Z",
     "start_time": "2024-11-27T17:05:23.505428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Iterate through the dataset to extract labels\n",
    "labels = []\n",
    "\n",
    "for inputs, label in dataset_method_I:\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert to a tensor or numpy array\n",
    "y_train = np.concatenate(labels, axis=0)  # Stack labels into a single array\n",
    "y_train_flat = y_train.reshape(-1, 6)  # Flattening the labels: (num_samples * 10, 6)\n",
    "y_train_classes = np.argmax(y_train_flat, axis=-1)  # Get the class labels for each timestep (0 to 5)\n",
    "\n",
    "# Calculate class weights based on the frequency of each class\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_classes), y=y_train_classes)\n",
    "\n",
    "# Convert class_weights into a dictionary format for fit() function\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ],
   "id": "f84b4dd1b5357177",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:05:25.574631Z",
     "start_time": "2024-11-27T17:05:25.568392Z"
    }
   },
   "cell_type": "code",
   "source": "print(class_weights)",
   "id": "d45925f5ce6896ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.69060938e-01 2.54473304e+01 2.90288066e+01 5.34393939e+02\n",
      " 2.02701149e+02 2.26089744e+02]\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:05:26.584316Z",
     "start_time": "2024-11-27T17:05:26.575240Z"
    }
   },
   "cell_type": "code",
   "source": "print(class_weight_dict)",
   "id": "1123818c70420704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.1690609376722605, 1: 25.447330447330447, 2: 29.02880658436214, 3: 534.3939393939394, 4: 202.70114942528735, 5: 226.0897435897436}\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:02:07.266954Z",
     "start_time": "2024-11-27T17:00:52.846821Z"
    }
   },
   "cell_type": "code",
   "source": "history = model_I.fit(dataset_method_I, epochs=50, batch_size=BATCH_SIZE, class_weight=class_weight_dict)",
   "id": "19ccb585dcf4bcaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.0157 - loss: 34.8963\n",
      "Epoch 2/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0505 - loss: 33.9349\n",
      "Epoch 3/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0398 - loss: 26.3637\n",
      "Epoch 4/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0117 - loss: 15.2358\n",
      "Epoch 5/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0345 - loss: 21.1825\n",
      "Epoch 6/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0211 - loss: 22.3715\n",
      "Epoch 7/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.0732 - loss: 24.3817\n",
      "Epoch 8/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.0372 - loss: 9.8767\n",
      "Epoch 9/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - accuracy: 0.0362 - loss: 22.6543\n",
      "Epoch 10/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0925 - loss: 20.0380\n",
      "Epoch 11/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0062 - loss: 21.0310\n",
      "Epoch 12/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0047 - loss: 9.9892\n",
      "Epoch 13/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0499 - loss: 14.0161\n",
      "Epoch 14/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0089 - loss: 22.4233\n",
      "Epoch 15/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0081 - loss: 12.8623\n",
      "Epoch 16/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.0224 - loss: 21.0673\n",
      "Epoch 17/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step - accuracy: 0.0192 - loss: 14.8669\n",
      "Epoch 18/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0277 - loss: 27.6578\n",
      "Epoch 19/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0131 - loss: 17.0767\n",
      "Epoch 20/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0170 - loss: 9.6139\n",
      "Epoch 21/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0022 - loss: 13.2179\n",
      "Epoch 22/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0132 - loss: 13.7602\n",
      "Epoch 23/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0212 - loss: 6.2061\n",
      "Epoch 24/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0156 - loss: 13.1043\n",
      "Epoch 25/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0443 - loss: 10.5961\n",
      "Epoch 26/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0287 - loss: 11.8871\n",
      "Epoch 27/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0427 - loss: 17.6457\n",
      "Epoch 28/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 16ms/step - accuracy: 0.0029 - loss: 11.8749\n",
      "Epoch 29/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 15ms/step - accuracy: 0.0420 - loss: 14.9934\n",
      "Epoch 30/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 13ms/step - accuracy: 0.1112 - loss: 21.3939\n",
      "Epoch 31/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0106 - loss: 15.2655\n",
      "Epoch 32/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0128 - loss: 17.7346\n",
      "Epoch 33/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.1159 - loss: 19.4642\n",
      "Epoch 34/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0598 - loss: 14.9241\n",
      "Epoch 35/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0734 - loss: 83.5409\n",
      "Epoch 36/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.1010 - loss: 26.0593\n",
      "Epoch 37/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0046 - loss: 17.4360\n",
      "Epoch 38/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 12ms/step - accuracy: 0.0728 - loss: 12.6230\n",
      "Epoch 39/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 13ms/step - accuracy: 0.0275 - loss: 11.9846\n",
      "Epoch 40/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.0059 - loss: 11.4789\n",
      "Epoch 41/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.0125 - loss: 14.7179\n",
      "Epoch 42/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.1290 - loss: 22.5434\n",
      "Epoch 43/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.0113 - loss: 17.2917\n",
      "Epoch 44/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 14ms/step - accuracy: 0.0428 - loss: 14.7984\n",
      "Epoch 45/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 16ms/step - accuracy: 0.0183 - loss: 20.5429\n",
      "Epoch 46/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - accuracy: 0.0160 - loss: 10.8529\n",
      "Epoch 47/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 16ms/step - accuracy: 0.0126 - loss: 12.4679\n",
      "Epoch 48/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - accuracy: 0.0110 - loss: 15.2946\n",
      "Epoch 49/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 18ms/step - accuracy: 0.0165 - loss: 24.6349\n",
      "Epoch 50/50\n",
      "\u001B[1m112/112\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 17ms/step - accuracy: 0.0124 - loss: 13.1240\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:02:10.538087Z",
     "start_time": "2024-11-27T17:02:10.499255Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.summary()",
   "id": "6235f654319c897",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda_9 (\u001B[38;5;33mLambda\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m515\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │       \u001B[38;5;34m148,480\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m6\u001B[0m)          │           \u001B[38;5;34m198\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">515</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m452,276\u001B[0m (1.73 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452,276</span> (1.73 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m150,758\u001B[0m (588.90 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,758</span> (588.90 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m301,518\u001B[0m (1.15 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,518</span> (1.15 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:02:15.013626Z",
     "start_time": "2024-11-27T17:02:13.394851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, acc = model_I.evaluate(MAAP_test_method_I, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(acc))"
   ],
   "id": "8b4a500ad36da8b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 - 2s - 44ms/step - accuracy: 7.4824e-04 - loss: 3.5723\n",
      "Untrained model, accuracy:  0.00%\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T17:02:18.313606Z",
     "start_time": "2024-11-27T17:02:17.705355Z"
    }
   },
   "cell_type": "code",
   "source": "model_I.save(os.path.join(path, 'model_method_I/model.keras'))",
   "id": "914d4b9b7968270e",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MODEL II",
   "id": "b53443af5c334d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:25:17.428441Z",
     "start_time": "2024-11-26T23:25:17.262518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_II = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM)),    # Input shape: (sequence_length, features)\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),              # LSTM layer to capture temporal patterns\n",
    "    tf.keras.layers.Dense(32, activation='relu'),                 # Dense layer to reduce dimensionality\n",
    "    tf.keras.layers.Dense(OUTPUT_DIM, activation='sigmoid')       # Output layer with sigmoid for continuous values between 0 and 1\n",
    "])"
   ],
   "id": "8ae51ea52a2bf3b6",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def mask_timestep(inputs):\n",
    "    # Mask timesteps where any feature is 0\n",
    "    # tf.reduce_any checks if any feature in the timestep is 0\n",
    "    mask = tf.reduce_any(tf.equal(inputs, 0.0), axis=-1)  # Create mask for timesteps with any 0\n",
    "    return mask\n",
    "\n",
    "# Input Layer\n",
    "inputs = tf.keras.Input(shape=(SEQUENCE_LENGTH, INPUT_DIM))\n",
    "\n",
    "# Apply the custom masking logic\n",
    "mask = tf.keras.layers.Lambda(mask_timestep)(inputs)\n",
    "\n",
    "# Apply the mask to the input sequence (this will zero out timesteps that have missing values)\n",
    "masked_inputs = tf.keras.layers.Masking(mask_value=0.0)(inputs)\n",
    "\n",
    "# LSTM layers to process the masked inputs\n",
    "lstm_output = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(masked_inputs)\n",
    "\n",
    "# Dense layers\n",
    "dense_output = tf.keras.layers.Dense(32, activation='relu')(lstm_output)\n",
    "output = tf.keras.layers.Dense(OUTPUT_DIM, activation='sigmoid')(dense_output)\n",
    "\n",
    "# Build and compile the model\n",
    "model_I = tf.keras.Model(inputs=inputs, outputs=output)"
   ],
   "id": "5be0ce81f4096c19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:25:17.691757Z",
     "start_time": "2024-11-26T23:25:17.660288Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])",
   "id": "372ce70cf7533e58",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:28:32.534032Z",
     "start_time": "2024-11-26T23:25:17.823809Z"
    }
   },
   "cell_type": "code",
   "source": "history = model_II.fit(dataset_method_II, epochs=50)",
   "id": "90c6f6be681e7739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 24ms/step - loss: 0.0663 - mae: 0.1861\n",
      "Epoch 2/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 20ms/step - loss: 0.0117 - mae: 0.0421\n",
      "Epoch 3/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0108 - mae: 0.0378\n",
      "Epoch 4/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - loss: 0.0104 - mae: 0.0362\n",
      "Epoch 5/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0096 - mae: 0.0343\n",
      "Epoch 6/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - loss: 0.0094 - mae: 0.0339\n",
      "Epoch 7/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - loss: 0.0089 - mae: 0.0328\n",
      "Epoch 8/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0085 - mae: 0.0318\n",
      "Epoch 9/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0083 - mae: 0.0310\n",
      "Epoch 10/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0079 - mae: 0.0297\n",
      "Epoch 11/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0077 - mae: 0.0292\n",
      "Epoch 12/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0075 - mae: 0.0284\n",
      "Epoch 13/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - loss: 0.0075 - mae: 0.0279\n",
      "Epoch 14/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0075 - mae: 0.0278\n",
      "Epoch 15/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 14ms/step - loss: 0.0071 - mae: 0.0270\n",
      "Epoch 16/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 13ms/step - loss: 0.0068 - mae: 0.0264\n",
      "Epoch 17/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 15ms/step - loss: 0.0068 - mae: 0.0262\n",
      "Epoch 18/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0066 - mae: 0.0256\n",
      "Epoch 19/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0065 - mae: 0.0255\n",
      "Epoch 20/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0064 - mae: 0.0250\n",
      "Epoch 21/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - loss: 0.0064 - mae: 0.0246\n",
      "Epoch 22/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0062 - mae: 0.0241\n",
      "Epoch 23/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - loss: 0.0060 - mae: 0.0240\n",
      "Epoch 24/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0061 - mae: 0.0240\n",
      "Epoch 25/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 19ms/step - loss: 0.0059 - mae: 0.0234\n",
      "Epoch 26/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0061 - mae: 0.0237\n",
      "Epoch 27/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0060 - mae: 0.0232\n",
      "Epoch 28/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0059 - mae: 0.0233\n",
      "Epoch 29/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0057 - mae: 0.0226\n",
      "Epoch 30/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0057 - mae: 0.0224\n",
      "Epoch 31/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0057 - mae: 0.0229\n",
      "Epoch 32/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0057 - mae: 0.0222\n",
      "Epoch 33/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0056 - mae: 0.0224\n",
      "Epoch 34/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0055 - mae: 0.0222\n",
      "Epoch 35/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0054 - mae: 0.0218\n",
      "Epoch 36/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0055 - mae: 0.0219\n",
      "Epoch 37/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0054 - mae: 0.0221\n",
      "Epoch 38/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0053 - mae: 0.0216\n",
      "Epoch 39/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0051 - mae: 0.0210\n",
      "Epoch 40/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0053 - mae: 0.0215\n",
      "Epoch 41/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0052 - mae: 0.0213\n",
      "Epoch 42/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0054 - mae: 0.0217\n",
      "Epoch 43/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0052 - mae: 0.0210\n",
      "Epoch 44/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0052 - mae: 0.0213\n",
      "Epoch 45/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0050 - mae: 0.0207\n",
      "Epoch 46/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0052 - mae: 0.0213\n",
      "Epoch 47/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0051 - mae: 0.0208\n",
      "Epoch 48/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 18ms/step - loss: 0.0055 - mae: 0.0215\n",
      "Epoch 49/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 17ms/step - loss: 0.0053 - mae: 0.0213\n",
      "Epoch 50/50\n",
      "\u001B[1m225/225\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 16ms/step - loss: 0.0049 - mae: 0.0203\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:28:32.648433Z",
     "start_time": "2024-11-26T23:28:32.604868Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.summary()",
   "id": "a934e87493baa466",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │       \u001B[38;5;34m148,480\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m32\u001B[0m)         │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m6\u001B[0m)          │           \u001B[38;5;34m198\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m452,276\u001B[0m (1.73 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452,276</span> (1.73 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m150,758\u001B[0m (588.90 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150,758</span> (588.90 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m301,518\u001B[0m (1.15 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,518</span> (1.15 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:28:35.993762Z",
     "start_time": "2024-11-26T23:28:32.790172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "loss, acc = model_II.evaluate(MAAP_test_method_II, verbose=2)\n",
    "print(\"Untrained model, coherence: {:5.2f}%\".format(100 * (1-acc)))"
   ],
   "id": "5d5d5465ef467740",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 - 3s - 44ms/step - loss: 0.0120 - mae: 0.0367\n",
      "Untrained model, coherence: 96.33%\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:28:36.389984Z",
     "start_time": "2024-11-26T23:28:36.081329Z"
    }
   },
   "cell_type": "code",
   "source": "model_II.save(os.path.join(path, 'model_method_II/model.keras'))",
   "id": "4f814446e3673c61",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "ef738c8d809ab7ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:51:43.871518Z",
     "start_time": "2024-11-27T00:51:43.854370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout"
   ],
   "id": "4aee6213cfffbc5",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.218835Z",
     "start_time": "2024-11-27T01:00:10.208197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_positional_encoding(sequence_length, input_dim):\n",
    "    \"\"\"\n",
    "    Generate a positional encoding matrix for the transformer model.\n",
    "    This encoding is added to the input data to give the model an understanding of the order of the sequence.\n",
    "    \"\"\"\n",
    "    position = np.arange(sequence_length)[:, np.newaxis]  # Shape: (sequence_length, 1)\n",
    "    div_term = np.exp(np.arange(0, input_dim, 2) * -(np.log(10000.0) / input_dim))  # Shape: (input_dim // 2,)\n",
    "    \n",
    "    pos_enc = np.zeros((sequence_length, input_dim))  # Shape: (sequence_length, input_dim)\n",
    "    \n",
    "    # Apply sine to even indices (0, 2, 4, ...)\n",
    "    pos_enc[:, 0::2] = np.sin(position * div_term)  # Apply sine to even indices (0, 2, 4, ...)\n",
    "    pos_enc[:, 1::2] = np.cos(position * div_term)\n",
    "    # Apply cosine to odd indices (1, 3, 5, ...)\n",
    "    if input_dim % 2 != 0:  # Even input_dim\n",
    "        pos_enc[:, -1] = np.sin(position * div_term[-1])  # If odd, handle the last dimension separately\n",
    "\n",
    "    return tf.constant(pos_enc, dtype=tf.float32)\n",
    "\n"
   ],
   "id": "5d0c84a9b72f3415",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.829573Z",
     "start_time": "2024-11-27T01:00:10.813862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout_rate):\n",
    "    # Multi-Head Self Attention Layer\n",
    "    attention_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout_rate)(inputs, inputs)\n",
    "    \n",
    "    # Skip connection and normalization\n",
    "    x = tf.keras.layers.Add()([inputs, attention_output])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    # Feed-forward network\n",
    "    ffn_output = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
    "    ffn_output = tf.keras.layers.Dense(inputs.shape[-1])(ffn_output)\n",
    "    \n",
    "    # Skip connection and normalization\n",
    "    x = tf.keras.layers.Add()([x, ffn_output])\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    \n",
    "    return x"
   ],
   "id": "78127408d3a5f6b4",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:10.880936Z",
     "start_time": "2024-11-27T01:00:10.869590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_transformer_model(sequence_length, input_dim, output_dim, num_heads=8, ff_dim=128, num_layers=4, dropout_rate=0.1):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, input_dim))  # Input shape\n",
    "    \n",
    "    # Add positional encoding to inputs\n",
    "    pos_encoding = get_positional_encoding(sequence_length, input_dim)\n",
    "    x = tf.keras.layers.Add()([inputs, pos_encoding])  # Adding positional encoding to input\n",
    "    \n",
    "    # Pass through multiple Transformer encoder blocks\n",
    "    for _ in range(num_layers):\n",
    "        x = transformer_encoder(x, head_size=input_dim, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    output = tf.keras.layers.Dense(output_dim, activation='sigmoid')(x)  # Output layer with 6 emotions\n",
    "    \n",
    "    # Build the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ],
   "id": "2acefd7865f5d0ae",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T01:00:11.690059Z",
     "start_time": "2024-11-27T01:00:11.609319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset dimensions (example values)\n",
    "sequence_length = 10  # Length of each sequence (e.g., 10 frames per video)\n",
    "input_dim = 515  # Number of features per timestep (e.g., face embeddings with 515 features)\n",
    "output_dim = 6  # Number of classes (emotions)\n",
    "\n",
    "# Build the model\n",
    "model = build_transformer_model(sequence_length, input_dim, output_dim)"
   ],
   "id": "2ee64a4daf5a35b8",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,258) into shape (10,257)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[105], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m output_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m6\u001B[39m  \u001B[38;5;66;03m# Number of classes (emotions)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Build the model\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_transformer_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[104], line 5\u001B[0m, in \u001B[0;36mbuild_transformer_model\u001B[1;34m(sequence_length, input_dim, output_dim, num_heads, ff_dim, num_layers, dropout_rate)\u001B[0m\n\u001B[0;32m      2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(sequence_length, input_dim))  \u001B[38;5;66;03m# Input shape\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Add positional encoding to inputs\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m pos_encoding \u001B[38;5;241m=\u001B[39m \u001B[43mget_positional_encoding\u001B[49m\u001B[43m(\u001B[49m\u001B[43msequence_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_dim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m x \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mAdd()([inputs, pos_encoding])  \u001B[38;5;66;03m# Adding positional encoding to input\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Pass through multiple Transformer encoder blocks\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[102], line 13\u001B[0m, in \u001B[0;36mget_positional_encoding\u001B[1;34m(sequence_length, input_dim)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Apply sine to even indices (0, 2, 4, ...)\u001B[39;00m\n\u001B[0;32m     12\u001B[0m pos_enc[:, \u001B[38;5;241m0\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msin(position \u001B[38;5;241m*\u001B[39m div_term)  \u001B[38;5;66;03m# Apply sine to even indices (0, 2, 4, ...)\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[43mpos_enc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcos(position \u001B[38;5;241m*\u001B[39m div_term)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Apply cosine to odd indices (1, 3, 5, ...)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_dim \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m# Even input_dim\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: could not broadcast input array from shape (10,258) into shape (10,257)"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Assuming you have `X_train` and `y_train` loaded from your dataset\n",
    "# Model training\n",
    "history = model.fit(dataset_method_I,epochs=50, batch_size=32)"
   ],
   "id": "53f62401fe8c9038"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5d887569df7289f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
